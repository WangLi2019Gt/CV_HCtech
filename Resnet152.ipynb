{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.hub import load_state_dict_from_url\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "    'resnext50_32x4d': 'https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth',\n",
    "    'resnext101_32x8d': 'https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth',\n",
    "    'wide_resnet50_2': 'https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth',\n",
    "    'wide_resnet101_2': 'https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth',\n",
    "}\n",
    "def conv3x3(in_planes, out_planes, stride=1, padding=1):\n",
    "  return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=padding, bias=False)  #? Why no bias\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "  return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False) #? Why no bias: 如果卷积层之后是BN层，那么可以不用偏置参数，可以节省内存\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "  expansion = 1 # 经过Block之后channel的变化量\n",
    "\n",
    "  def __init__(self, inplanes, planes, stride=1, downsample=None, norm_layer=None):\n",
    "    # downsample: 调整维度一致之后才能相加\n",
    "    # norm_layer：batch normalization layer\n",
    "    super(BasicBlock, self).__init__()\n",
    "    if norm_layer is None:\n",
    "      norm_layer = nn.BatchNorm2d # 如果bn层没有自定义，就使用标准的bn层\n",
    "    self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "    self.bn1 = norm_layer(planes)\n",
    "    self.relu = nn.ReLU(inplace=True)\n",
    "    self.conv2 = conv3x3(planes, planes)\n",
    "    self.bn2 = norm_layer(planes)\n",
    "    self.downsample = downsample\n",
    "    self.stride = stride\n",
    "\n",
    "  def forward(self, x):\n",
    "    identity = x  # 保存x\n",
    "\n",
    "    out = self.conv1(x)\n",
    "    out = self.bn1(out)\n",
    "    out = self.relu(out)\n",
    "\n",
    "    out = self.conv2(out)\n",
    "    out = self.bn2(out)\n",
    "\n",
    "    if self.downsample is not None:\n",
    "      identity = self.downsample(x)  # downsample调整x的维度，F(x)+x一致才能相加\n",
    "    \n",
    "    out += identity\n",
    "    out = self.relu(out) # 先相加再激活\n",
    "\n",
    "    return out\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "  expansion = 4\n",
    "\n",
    "  def __init__(self, inplanes, planes, stride=1, downsample=None, norm_layer=None):\n",
    "    super(Bottleneck, self).__init__()\n",
    "    if norm_layer is None:\n",
    "      norm_layer = nn.BatchNorm2d\n",
    "    \n",
    "    self.conv1 = conv1x1(inplanes, planes)\n",
    "    self.bn1 = norm_layer(planes)\n",
    "    self.conv2 = conv3x3(planes, planes, stride)\n",
    "    self.bn2 = norm_layer(planes)\n",
    "    self.conv3 = conv1x1(planes, planes * self.expansion) # 输入的channel数：planes * self.expansion\n",
    "    self.bn3 = norm_layer(planes * self.expansion)\n",
    "    self.relu = nn.ReLU(inplace=True)\n",
    "    self.downsample = downsample\n",
    "    self.stride = stride\n",
    "\n",
    "  def forward(self, x):\n",
    "    identity = x\n",
    "\n",
    "    out = self.conv1(x)\n",
    "    out = self.bn1(out)\n",
    "    out = self.relu(out)\n",
    "\n",
    "    out = self.conv2(out)\n",
    "    out = self.bn2(out)\n",
    "    out = self.relu(out)\n",
    "\n",
    "    out = self.conv3(out)\n",
    "    out = self.bn3(out)\n",
    "    \n",
    "    if self.downsample is not None:\n",
    "      identity = self.downsample(x)\n",
    "\n",
    "    out += identity\n",
    "    out = self.relu(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "  def __init__(self, block, layers, num_class=1000, norm_layer=None):\n",
    "    super(ResNet, self).__init__()\n",
    "    if norm_layer is None:\n",
    "      norm_layer = nn.BatchNorm2d\n",
    "    self._norm_layer = norm_layer\n",
    "\n",
    "    self.inplanes = 64\n",
    "\n",
    "    # conv1 in ppt figure\n",
    "    self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    self.bn1 = norm_layer(self.inplanes)\n",
    "    self.relu = nn.ReLU(inplace=True)\n",
    "    self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "    self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "    self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "    self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "    self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "    self.avgpool = nn.AdaptiveAvgPool2d((1,1))  # (1,1)等于GAP\n",
    "    self.fc = nn.Linear(512*block.expansion, num_class)\n",
    "\n",
    "    for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "  def _make_layer(self, block, planes, blocks, stride=1):\n",
    "    # 生成不同的stage/layer\n",
    "    # block: block type(basic block/bottle block)\n",
    "    # blocks: blocks的数量\n",
    "    norm_layer = self._norm_layer\n",
    "    downsample = None\n",
    "\n",
    "    if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "      # 需要调整维度\n",
    "      downsample = nn.Sequential(\n",
    "          conv1x1(self.inplanes, planes * block.expansion, stride),  # 同时调整spatial(H x W))和channel两个方向\n",
    "          norm_layer(planes * block.expansion)\n",
    "      )\n",
    "\n",
    "    layers = []\n",
    "    layers.append(block(self.inplanes, planes, stride, downsample, norm_layer)) # 第一个block单独处理\n",
    "    self.inplanes = planes * block.expansion  # 记录layerN的channel变化，具体请看ppt resnet表格\n",
    "    for _ in range(1, blocks): # 从1开始循环，因为第一个模块前面已经单独处理\n",
    "      layers.append(block(self.inplanes, planes, norm_layer=norm_layer))\n",
    "    return nn.Sequential(*layers)  # 使用Sequential层组合blocks，形成stage。如果layers=[2,3,4]，那么*layers=？\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.bn1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.maxpool(x)\n",
    "\n",
    "    x = self.layer1(x)\n",
    "    x = self.layer2(x)\n",
    "    x = self.layer3(x)\n",
    "    x = self.layer4(x)\n",
    "\n",
    "    x = self.avgpool(x)\n",
    "    x = torch.flatten(x, 1)\n",
    "    x = self.fc(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def _resnet(arch, block, layers, pretrained, progress, **kwargs):\n",
    "    model = ResNet(block, layers, **kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet18(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"ResNet-18 model from\n",
    "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress,\n",
    "                   **kwargs)\n",
    "\n",
    "def resnet50(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"ResNet-50 model from\n",
    "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet('resnet50', Bottleneck, [3, 4, 6, 3], pretrained, progress,\n",
    "                   **kwargs)\n",
    "\n",
    "def resnet152(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"ResNet-152 model from\n",
    "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet('resnet152', Bottleneck, [3, 8, 36, 3], pretrained, progress,\n",
    "                   **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (23): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (24): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (25): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (26): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (27): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (28): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (29): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (30): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (31): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (32): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (33): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (34): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (35): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet152(pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rogqigx171/.cache/torch/hub/pytorch_vision_v0.4.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (23): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (24): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (25): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (26): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (27): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (28): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (29): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (30): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (31): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (32): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (33): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (34): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (35): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = torch.hub.load('pytorch/vision:v0.4.2', 'resnet152', pretrained=True)\n",
    "model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.6715e-01, -7.1970e-01, -1.1477e+00, -1.4235e+00, -2.3382e+00,\n",
      "         1.3198e+00, -8.5561e-01,  1.9753e+00,  4.7764e+00, -1.5662e-01,\n",
      "        -9.2236e-01, -6.4763e-01, -1.4888e+00, -9.3758e-01, -3.3264e-01,\n",
      "        -1.2148e+00, -1.0260e+00,  1.5018e+00,  3.0635e-01, -7.9825e-01,\n",
      "        -1.4174e+00, -7.2353e-01, -1.8555e+00, -4.3315e-02, -2.2541e+00,\n",
      "        -5.4571e-01,  1.2344e-01,  6.8431e-01, -7.2438e-01,  3.0649e+00,\n",
      "        -3.7269e-01,  1.7250e-01,  1.4965e+00, -1.8406e+00, -1.1434e-01,\n",
      "        -9.1618e-01, -1.4046e+00, -9.8438e-01, -1.4462e-01, -5.3998e-01,\n",
      "        -1.5295e+00, -1.9589e+00, -2.4135e+00, -2.1158e+00, -1.2151e-01,\n",
      "        -9.3840e-01,  6.4887e-01, -7.0536e-01, -3.1816e+00, -1.2064e+00,\n",
      "        -1.2384e+00, -1.4129e+00,  5.9586e-01, -2.7741e+00, -5.9331e-01,\n",
      "        -8.8087e-01, -7.7742e-01, -1.8902e-01, -5.2709e-01, -1.3785e+00,\n",
      "         1.3683e+00, -1.4733e+00, -2.3232e+00, -2.6685e+00, -1.2786e+00,\n",
      "        -1.3968e+00, -3.7588e-01, -2.3240e+00, -1.2900e+00, -3.1433e+00,\n",
      "        -1.2508e+00,  3.4481e-01, -2.1857e+00, -7.6116e-01, -1.1072e+00,\n",
      "        -5.4388e-01, -1.4990e+00, -1.0113e+00,  2.7084e+00,  1.6177e+00,\n",
      "        -6.2918e-01,  1.7059e-01,  5.6959e-01, -8.3642e-01,  5.1573e-01,\n",
      "        -3.5493e-01,  2.9007e-01, -1.5159e+00, -1.5285e+00,  1.1817e+00,\n",
      "        -1.7718e+00, -1.7817e+00, -3.0281e+00, -1.5648e+00, -1.4278e+00,\n",
      "        -2.9525e+00, -1.6395e+00, -1.8020e+00, -2.6962e+00, -7.0659e-01,\n",
      "         8.7182e-01, -2.5566e+00,  2.0441e-01, -2.8165e+00,  4.1807e+00,\n",
      "        -1.2253e+00,  1.8673e+00, -1.0163e+00,  6.9645e-01, -3.4444e+00,\n",
      "         6.8967e-02, -1.7000e+00,  1.0739e+00,  1.1161e-01,  5.3168e-01,\n",
      "         1.6918e-01, -2.1360e+00, -6.6472e-01, -5.2803e-01, -2.0712e-01,\n",
      "        -1.8586e+00, -6.4501e-01,  3.4128e-01, -5.7678e-01, -3.4810e-02,\n",
      "        -7.7270e-01,  3.4117e-01, -4.3863e-01, -2.8679e+00,  1.8149e-02,\n",
      "        -5.2458e-01, -1.9694e+00, -4.0739e-01, -2.6458e+00, -2.5536e+00,\n",
      "        -2.1011e+00, -4.7708e-01, -1.6839e+00, -2.6292e+00, -1.5264e+00,\n",
      "        -2.7248e+00, -2.0679e+00, -2.5157e+00, -1.5359e-01, -4.8687e-01,\n",
      "        -1.4127e+00, -1.1092e+00, -2.2251e+00, -2.4315e+00, -1.8469e+00,\n",
      "        -2.3177e+00,  5.4603e+00,  6.4517e+00,  3.2629e+00,  4.9733e+00,\n",
      "         6.9705e-01,  8.8361e-01,  5.8224e+00,  1.7464e+00,  2.1710e-01,\n",
      "        -8.1869e-01, -1.6929e+00, -1.3331e+00, -1.5282e+00, -2.0995e-01,\n",
      "        -2.2677e+00, -6.9262e-01, -2.4999e+00, -6.2800e-01,  2.6448e+00,\n",
      "         9.8245e-01, -9.2124e-01, -1.5870e+00,  2.8520e-01,  3.4893e+00,\n",
      "         3.7509e-01, -1.5688e+00, -9.0667e-01, -1.0511e+00,  7.4924e-01,\n",
      "         1.2978e+00, -1.6814e+00,  9.5201e-01, -1.0521e+00, -3.0612e-01,\n",
      "         3.0704e+00,  4.6679e+00,  1.1383e+00,  1.2909e+00, -6.5094e-01,\n",
      "         1.0984e-01, -7.8735e-01,  3.9486e+00,  3.5245e+00, -1.5877e-01,\n",
      "         1.0021e+00, -1.2646e+00, -1.0964e+00, -1.9090e+00,  2.8624e+00,\n",
      "         1.3707e+00,  1.6547e+00, -2.1610e-01,  4.9648e+00,  1.3348e+00,\n",
      "        -2.9454e-01, -1.5917e+00,  2.9863e+00,  8.9196e-01, -7.4773e-01,\n",
      "        -1.3632e+00,  1.1665e-01,  1.2619e+00, -3.0106e-01, -5.1495e-02,\n",
      "         1.0324e+00,  1.8423e+00, -2.2598e-01, -1.6475e-02, -1.2124e+00,\n",
      "         8.9089e-01, -1.5621e+00,  5.9844e+00,  6.4734e+00,  5.5679e+00,\n",
      "         5.4751e-01,  2.6045e+00,  2.6590e+00,  3.2119e+00,  2.0422e+00,\n",
      "         5.9178e+00,  6.2380e+00,  5.7135e+00,  8.4527e-01, -1.2045e-01,\n",
      "         3.9483e+00,  2.1590e+00,  6.4484e-01, -7.4500e-01,  1.1693e+00,\n",
      "         9.2486e-01,  3.3494e-01,  3.2979e-01, -1.4854e+00,  2.1686e+00,\n",
      "        -7.7058e-02,  1.4600e-01,  2.0207e+00,  7.8608e+00,  5.7074e+00,\n",
      "         5.8551e+00,  2.5493e+00,  1.2724e+00,  1.3632e+00,  3.5348e-01,\n",
      "         5.3063e-01,  2.8637e+00,  6.6813e+00,  1.2603e+01,  1.0427e+01,\n",
      "         6.0704e+00,  9.2189e+00,  5.9372e-01,  4.2457e+00,  2.1745e+00,\n",
      "         2.4705e+00,  2.0013e+00,  2.0485e+00, -9.1465e-01,  5.4834e+00,\n",
      "         9.5163e+00,  1.5076e+00,  2.6274e+00,  3.4745e+00,  4.7528e+00,\n",
      "         7.1613e-01,  1.1290e+00,  2.7497e+00,  2.5098e+00,  9.0562e+00,\n",
      "         3.7402e+00,  2.7532e+00,  2.9333e+00,  6.2140e+00,  8.3414e-01,\n",
      "         2.1061e+00, -1.1685e+00,  3.1228e+00,  8.5177e-01,  2.4144e+00,\n",
      "        -2.1198e-01,  2.1424e+00,  2.0387e+00,  1.4860e+00, -1.6665e-01,\n",
      "        -9.2356e-02,  1.8721e+00,  1.0602e-01, -4.6454e-03, -3.1264e-01,\n",
      "        -1.8601e+00, -1.2249e+00, -1.2163e+00, -1.1319e+00, -9.5160e-01,\n",
      "        -2.2890e+00,  2.6274e-01, -2.1494e-01, -3.3256e+00, -1.0493e+00,\n",
      "         1.1871e+00, -3.8781e-01, -1.1691e+00, -2.6291e-01,  6.1630e-02,\n",
      "        -1.8986e+00, -1.3168e+00,  2.8846e-01, -2.5870e-01, -3.0426e+00,\n",
      "        -1.8248e+00, -2.0732e+00, -1.9572e+00, -1.4870e+00, -1.1264e+00,\n",
      "         1.2805e-01, -4.9419e-01,  5.7170e-01,  3.1508e-01, -2.3021e-01,\n",
      "         2.1116e+00,  4.1417e+00,  5.8910e+00,  4.0454e+00,  1.6309e+00,\n",
      "         2.0468e+00, -3.2016e-01,  5.1478e-02,  2.0781e+00, -6.2190e-01,\n",
      "        -5.1572e-01,  1.6447e+00, -2.8046e-01, -1.7984e+00, -2.2708e+00,\n",
      "         9.6790e-01,  3.7468e-01, -4.2509e-01,  1.5108e+00, -1.6600e+00,\n",
      "        -2.0905e+00, -2.7180e+00, -2.1259e+00, -3.0499e-01, -1.5070e+00,\n",
      "         2.1830e+00,  2.4020e+00,  2.3321e+00,  3.3574e+00,  2.5820e+00,\n",
      "        -1.8740e+00,  4.1936e+00,  1.3147e+00,  7.5473e-01, -2.2520e+00,\n",
      "        -1.6932e+00, -2.6662e+00, -6.2615e-01,  7.4366e-01, -8.4340e-01,\n",
      "        -1.5515e+00, -2.4772e-01, -8.8397e-01,  1.3240e+00, -1.0174e+00,\n",
      "        -2.1058e+00, -3.9270e+00,  2.0885e+00, -1.0221e+00, -1.2161e+00,\n",
      "         3.4124e-01, -1.1282e+00, -1.9041e-01,  9.9335e-01,  6.6256e-01,\n",
      "        -2.9327e+00, -5.4514e+00,  8.4152e-01, -1.4183e-01, -1.3495e+00,\n",
      "        -1.4917e+00, -3.7201e-01, -1.4351e+00, -2.1489e+00, -1.9982e+00,\n",
      "        -2.4381e+00, -1.1612e+00, -2.0218e+00,  4.4432e-01, -1.1711e+00,\n",
      "        -2.6305e+00,  6.3685e-01, -2.6331e-01, -1.7619e+00, -1.4464e+00,\n",
      "         2.3137e+00, -2.2795e+00, -2.7122e+00, -3.3218e-01,  2.7197e+00,\n",
      "        -2.3723e+00, -7.7473e-01,  3.9806e-01, -3.8488e-01, -1.1741e+00,\n",
      "        -1.2940e+00, -1.5075e+00,  1.1558e+00,  6.9144e-01,  1.1421e+00,\n",
      "         3.5634e-01, -1.1753e+00,  9.4099e-01, -3.4781e+00, -4.1069e+00,\n",
      "         4.8404e-01, -5.5461e-02,  1.9581e+00,  2.2295e+00,  2.8928e+00,\n",
      "        -2.4266e-02, -5.4963e-01, -1.8638e+00, -6.9512e-01, -2.3262e-01,\n",
      "         1.3969e+00, -8.8082e-01, -2.7454e-01, -1.5321e+00,  1.9214e+00,\n",
      "         9.9576e-02, -1.0130e+00,  3.4243e-01, -5.9417e-01,  9.0585e-01,\n",
      "         1.6219e+00,  5.8575e-01, -2.2210e+00, -6.4647e-02, -1.4085e+00,\n",
      "         3.0490e+00, -2.2756e+00,  5.1129e-01, -9.7291e-01, -1.8873e+00,\n",
      "        -2.3089e-01,  8.2205e-01,  1.0766e+00, -6.3817e-01,  6.6505e-01,\n",
      "        -7.2338e-01, -7.3132e-01,  1.1591e+00,  2.3472e+00, -9.4020e-01,\n",
      "        -1.0998e+00, -1.9053e+00, -3.1342e+00, -2.6468e-02,  3.2134e+00,\n",
      "         3.2143e+00,  6.4527e-01,  9.7968e-01,  9.7945e-02, -1.7363e+00,\n",
      "        -1.0759e+00,  1.8611e-01,  1.0358e-01,  1.5010e+00,  6.3617e-01,\n",
      "        -2.4552e+00, -3.0039e-02, -1.8832e+00, -8.0862e-02,  4.1741e-01,\n",
      "         2.5351e-01, -6.1729e-01, -1.2545e+00,  1.9837e+00,  1.2101e+00,\n",
      "        -1.5555e+00, -4.7125e-02, -1.3633e+00, -1.3047e+00,  1.3274e+00,\n",
      "        -1.1929e+00, -1.7667e-01, -5.2095e-01, -2.0366e+00,  9.8320e-01,\n",
      "        -3.8068e+00,  1.1176e+00,  1.5848e+00, -1.4249e+00,  6.7201e-01,\n",
      "         6.3927e-01, -3.7073e-01, -1.7475e-01,  1.5769e+00, -2.9809e+00,\n",
      "         3.7202e-01,  5.7863e-02,  5.4210e-01, -1.0188e+00, -2.3458e+00,\n",
      "         1.9288e+00, -3.9506e-01, -1.1869e+00, -3.9326e-04,  3.0694e-01,\n",
      "        -1.0726e+00,  1.0894e+00,  1.5293e+00, -1.5613e-01, -1.7208e+00,\n",
      "        -1.4248e+00, -1.8921e+00, -1.1062e+00,  3.8807e-01, -5.5422e-01,\n",
      "         1.8101e+00, -2.2319e+00, -3.3404e-01, -1.3242e+00,  4.8143e-01,\n",
      "         4.6952e-01, -1.0589e+00,  3.3979e+00, -7.9990e-01,  1.7354e+00,\n",
      "        -1.5151e+00,  9.3880e-01,  1.1667e+00,  6.5200e-01,  1.1745e+00,\n",
      "         9.1399e-01,  8.5929e-01, -4.2889e+00, -1.3312e+00, -6.0239e-01,\n",
      "        -2.3915e+00,  3.5007e-01,  3.1290e+00, -1.2662e+00,  1.0797e+00,\n",
      "        -1.4840e+00,  8.2921e-01,  5.4154e-01,  5.1505e-01,  1.4244e-01,\n",
      "         1.9161e+00, -1.0778e+00, -2.1398e-01, -6.7459e-01, -1.1371e+00,\n",
      "        -2.4435e+00, -4.6562e-01,  4.3253e-01,  4.4721e-01, -2.0810e+00,\n",
      "        -1.1294e+00, -3.0710e+00,  1.3388e+00,  9.7624e-01,  1.4029e+00,\n",
      "        -2.0888e+00, -2.0302e+00,  6.2748e-01,  8.5878e-02,  6.8300e-01,\n",
      "         3.3098e-01, -1.9538e+00, -1.2044e+00, -1.1416e+00, -6.4296e-02,\n",
      "         1.2240e+00, -1.1878e+00,  2.7924e-02, -1.4073e+00,  2.6692e-01,\n",
      "         2.0636e-01, -3.3039e-01, -1.1302e+00,  2.1691e-01,  1.4783e+00,\n",
      "        -2.0667e+00,  1.0854e+00, -9.9548e-01, -9.4511e-01, -2.2778e+00,\n",
      "         3.5939e-01,  4.4787e-01, -1.0381e+00, -1.5599e+00, -7.2636e-01,\n",
      "        -5.4177e-01,  1.7228e+00,  1.7371e+00,  2.4064e-01, -2.4865e+00,\n",
      "        -5.1316e-01,  1.2059e+00, -2.3950e+00, -5.7015e-01, -4.3394e-02,\n",
      "        -2.1415e-01, -5.8304e-01, -3.0858e-01,  3.6244e-01,  9.3229e-02,\n",
      "         7.9670e-02,  1.3712e+00,  1.4446e+00,  2.6511e-01, -1.2455e+00,\n",
      "         5.3220e-01, -3.9367e-02, -1.7267e+00,  8.3364e-01,  1.0540e+00,\n",
      "         3.2333e-02,  2.8939e+00,  1.2274e+00, -4.5704e-01, -1.8837e+00,\n",
      "         1.3110e+00,  6.2529e-02,  8.3211e-01,  1.5654e-01, -4.5221e-03,\n",
      "        -8.9832e-01,  9.4004e-01, -6.7775e-01,  3.4375e-01,  9.1070e-01,\n",
      "        -1.4470e+00,  9.3948e-01,  1.1870e+00, -1.0163e+00, -1.5932e+00,\n",
      "        -1.7587e+00, -1.0575e+00,  4.3204e-01,  3.0711e+00, -2.0934e+00,\n",
      "        -1.9722e-02, -1.3122e+00,  2.7711e+00,  4.5127e-01, -2.2057e-01,\n",
      "        -1.8114e+00, -1.1971e+00,  1.6999e+00, -2.6937e+00,  1.4300e+00,\n",
      "        -1.3469e+00,  6.0987e-01, -1.5825e-01, -7.7549e-01,  1.3699e-01,\n",
      "        -7.7675e-01, -6.2460e-01, -8.7960e-01,  1.0272e+00,  1.8567e+00,\n",
      "        -2.0737e+00,  2.9047e+00,  3.3306e-01, -1.3407e+00, -2.9588e-01,\n",
      "         2.2839e+00, -5.2406e-01, -1.6663e+00, -1.7864e-01,  4.8736e-01,\n",
      "        -4.4662e-01, -5.8747e-02, -1.1790e+00,  1.2367e+00, -1.1764e+00,\n",
      "        -3.1599e-01, -2.0872e+00,  2.0075e+00, -4.4235e-01, -2.3487e-01,\n",
      "        -6.4370e-01, -1.9021e+00, -6.1788e-01, -1.0122e+00,  1.1250e+00,\n",
      "         2.2512e+00, -3.5527e-01, -2.4621e+00,  1.0243e+00, -9.0271e-01,\n",
      "        -3.5686e+00, -1.2527e+00, -9.2588e-01,  1.2281e-01,  6.8144e-01,\n",
      "         1.1578e-01,  1.5908e+00,  6.7794e-01, -1.3145e+00, -5.2830e-01,\n",
      "        -2.1636e+00,  1.3797e+00, -2.4018e+00, -8.9641e-02,  2.6835e+00,\n",
      "         2.0517e-01,  6.0871e-01,  2.7685e+00,  7.1373e-01, -1.9223e+00,\n",
      "         6.6284e-02, -2.9092e+00, -9.6957e-01,  2.0154e+00, -1.2569e+00,\n",
      "         2.0502e-01,  8.8144e-01, -1.3943e+00,  3.2469e-01, -3.7161e+00,\n",
      "         7.5608e-01, -5.3477e-01, -7.1966e-01,  1.2117e+00, -2.2669e+00,\n",
      "        -1.6103e+00, -5.0678e-02,  1.4072e+00, -2.9870e+00,  1.5252e+00,\n",
      "        -1.6250e+00,  8.6496e-01,  8.0231e-01,  1.5040e+00,  1.5198e+00,\n",
      "         1.2369e+00,  9.7954e-01,  1.2776e+00,  1.2508e+00,  1.1569e-01,\n",
      "        -1.3217e+00,  1.8529e+00, -2.0304e+00, -1.7047e-01, -1.4921e+00,\n",
      "         5.5576e-01,  2.2901e+00, -1.9869e+00, -6.4925e-01,  3.7939e-01,\n",
      "         1.7989e+00, -6.5865e-02, -6.7037e-01,  3.8604e+00,  1.8338e+00,\n",
      "        -2.8090e-01, -8.2520e-01,  9.0498e-01,  9.1279e-01, -8.3900e-01,\n",
      "         1.1453e+00, -9.8827e-01, -7.5140e-02,  5.3872e-01, -2.8019e+00,\n",
      "         2.0465e-01,  3.1362e-01,  1.7132e+00,  8.4356e-01,  8.7977e-02,\n",
      "        -2.3196e-01,  2.5310e-01,  1.2633e+00, -5.0723e-01,  8.1283e-01,\n",
      "        -1.5444e+00, -1.9621e-01,  1.1905e+00, -2.2130e-01,  2.0300e-01,\n",
      "        -8.9328e-01, -1.2813e+00,  1.3759e+00, -8.0671e-01, -7.3499e-01,\n",
      "        -1.6508e+00, -1.4722e+00, -7.7341e-01, -1.4518e+00, -8.5254e-02,\n",
      "         3.3558e+00,  2.3741e-02,  9.4505e-01,  5.9002e-01,  2.4458e-01,\n",
      "         1.4543e+00,  2.6747e+00, -1.7194e+00, -5.5496e-01,  1.5051e+00,\n",
      "        -7.3446e-01,  3.7696e-01,  8.6076e-02, -1.3075e+00, -1.8302e+00,\n",
      "        -6.5815e-01, -1.6453e+00, -1.4907e-01,  2.8641e-01,  1.1313e+00,\n",
      "        -9.4144e-01,  1.6367e+00,  1.5353e+00,  8.5218e-01, -2.7696e+00,\n",
      "        -1.0609e+00,  1.1823e+00, -1.2564e+00,  3.7445e-01, -1.3422e+00,\n",
      "         1.1846e-01,  7.3154e-01,  1.2686e+00,  1.9672e+00, -1.1296e+00,\n",
      "        -1.4842e-01, -2.1066e-02, -1.5841e-01, -6.7893e-01,  2.2866e+00,\n",
      "         1.1475e+00, -1.0214e+00, -6.7582e-01, -8.0994e-01,  1.4964e+00,\n",
      "         3.6446e-01,  1.7352e+00,  4.4910e+00, -1.0063e+00, -1.4515e+00,\n",
      "         5.7857e-01, -1.5296e+00, -1.2428e+00, -1.3089e+00, -2.3003e-01,\n",
      "        -1.6860e+00,  6.3637e-01,  3.5886e-01, -2.1513e+00, -1.9229e+00,\n",
      "        -1.2923e+00,  1.5814e-01, -8.3755e-01,  8.4745e-01, -6.6790e-03,\n",
      "         1.2055e+00,  3.1710e-01,  4.8037e-02, -1.9604e+00, -4.1718e+00,\n",
      "        -1.1895e+00,  2.7798e+00, -1.5361e+00,  6.6478e-01,  1.8427e+00,\n",
      "         9.8394e-02, -9.4374e-01,  2.4514e-01, -2.8145e-01, -2.2334e+00,\n",
      "        -9.5114e-01, -1.5778e-01, -2.9992e+00, -3.2876e+00, -1.1735e+00,\n",
      "         2.1052e-01,  7.6343e-01,  1.6317e+00, -1.3791e+00, -9.2411e-01,\n",
      "        -2.4325e+00, -1.8494e+00, -8.3702e-01,  8.6649e-01,  7.0998e-01,\n",
      "         8.3494e-01, -9.7865e-01,  3.0327e+00, -5.8026e-01,  6.1925e-01,\n",
      "        -3.8380e-01, -2.3082e+00,  9.9495e-02, -1.1804e+00, -1.8899e-01,\n",
      "         7.6985e-02,  1.7285e+00,  2.2692e+00, -8.6363e-01, -3.7527e-01,\n",
      "        -4.2701e-01, -1.3947e-01, -2.0410e+00, -6.2954e-01, -1.4116e+00,\n",
      "        -1.9981e+00,  1.3466e+00, -1.4862e+00, -2.1212e-02, -7.1134e-01,\n",
      "        -2.9755e-01, -6.1230e-01, -7.3787e-01, -2.3162e+00,  1.7312e+00,\n",
      "        -7.1446e-01, -1.6237e+00, -6.9911e-01, -2.7586e+00,  7.2299e-01,\n",
      "         2.8798e-01,  5.0353e-01,  1.4315e+00,  1.2262e-01,  7.8143e-01,\n",
      "         1.1213e+00,  3.9525e-01,  1.1975e-01,  6.1121e-01, -4.4783e-01,\n",
      "        -1.1471e+00, -7.1760e-01,  2.7392e-01,  1.3773e+00,  6.1961e-01,\n",
      "        -6.3805e-01,  1.7515e-01, -6.0919e-01, -4.4040e-02, -6.7796e-01,\n",
      "        -1.4665e+00, -1.7949e-01,  2.4897e+00, -3.5933e-01,  1.1911e+00,\n",
      "        -2.4533e+00, -5.3648e-01, -1.0984e+00,  6.2527e-01, -2.3473e+00,\n",
      "        -1.5014e+00,  1.8501e+00, -2.2129e+00,  2.4850e+00, -5.8636e-02,\n",
      "        -7.4231e-01,  1.8365e+00, -1.1643e+00, -2.4197e+00, -7.7334e-01,\n",
      "         1.6578e+00,  4.9968e-01,  4.4637e-01, -1.3828e-01, -1.3986e+00,\n",
      "        -9.0130e-01, -4.7513e-02, -1.2249e+00, -1.6733e+00, -2.1522e+00,\n",
      "         2.9907e-01, -1.7415e-01,  1.5391e+00,  8.9820e-01, -2.0334e-01,\n",
      "         1.5348e-01,  8.9611e-01, -4.5365e-02, -3.6143e+00, -1.8741e+00,\n",
      "         1.7157e-01,  3.6912e-01, -1.8297e+00,  2.3445e-01,  2.1479e-01],\n",
      "       device='cuda:0')\n",
      "tensor([1.3643e-06, 1.2945e-06, 8.4374e-07, 6.4035e-07, 2.5655e-07, 9.9504e-06,\n",
      "        1.1300e-06, 1.9166e-05, 3.1551e-04, 2.2732e-06, 1.0570e-06, 1.3912e-06,\n",
      "        5.9990e-07, 1.0410e-06, 1.9063e-06, 7.8902e-07, 9.5297e-07, 1.1936e-05,\n",
      "        3.6116e-06, 1.1967e-06, 6.4429e-07, 1.2895e-06, 4.1575e-07, 2.5459e-06,\n",
      "        2.7906e-07, 1.5405e-06, 3.0079e-06, 5.2704e-06, 1.2884e-06, 5.6977e-05,\n",
      "        1.8314e-06, 3.1591e-06, 1.1873e-05, 4.2196e-07, 2.3713e-06, 1.0636e-06,\n",
      "        6.5259e-07, 9.9344e-07, 2.3006e-06, 1.5493e-06, 5.7597e-07, 3.7489e-07,\n",
      "        2.3794e-07, 3.2044e-07, 2.3544e-06, 1.0402e-06, 5.0869e-06, 1.3132e-06,\n",
      "        1.1039e-07, 7.9565e-07, 7.7057e-07, 6.4722e-07, 4.8242e-06, 1.6592e-07,\n",
      "        1.4689e-06, 1.1018e-06, 1.2219e-06, 2.2007e-06, 1.5694e-06, 6.6987e-07,\n",
      "        1.0445e-05, 6.0927e-07, 2.6044e-07, 1.8439e-07, 7.4018e-07, 6.5772e-07,\n",
      "        1.8256e-06, 2.6023e-07, 7.3180e-07, 1.1469e-07, 7.6110e-07, 3.7532e-06,\n",
      "        2.9881e-07, 1.2419e-06, 8.7862e-07, 1.5433e-06, 5.9379e-07, 9.6700e-07,\n",
      "        3.9892e-05, 1.3403e-05, 1.4171e-06, 3.1531e-06, 4.6992e-06, 1.1518e-06,\n",
      "        4.4527e-06, 1.8643e-06, 3.5533e-06, 5.8385e-07, 5.7655e-07, 8.6667e-06,\n",
      "        4.5201e-07, 4.4758e-07, 1.2869e-07, 5.5598e-07, 6.3763e-07, 1.3880e-07,\n",
      "        5.1599e-07, 4.3859e-07, 1.7935e-07, 1.3115e-06, 6.3574e-06, 2.0623e-07,\n",
      "        3.2615e-06, 1.5903e-07, 1.7390e-04, 7.8076e-07, 1.7203e-05, 9.6225e-07,\n",
      "        5.3347e-06, 8.4869e-08, 2.8484e-06, 4.8569e-07, 7.7813e-06, 2.9725e-06,\n",
      "        4.5243e-06, 3.1486e-06, 3.1404e-07, 1.3676e-06, 1.5679e-06, 2.1612e-06,\n",
      "        4.1446e-07, 1.3948e-06, 3.7399e-06, 1.4933e-06, 2.5676e-06, 1.2276e-06,\n",
      "        3.7395e-06, 1.7146e-06, 1.5106e-07, 2.7073e-06, 1.5734e-06, 3.7097e-07,\n",
      "        1.7690e-06, 1.8862e-07, 2.0685e-07, 3.2520e-07, 1.6499e-06, 4.9354e-07,\n",
      "        1.9178e-07, 5.7773e-07, 1.7430e-07, 3.3619e-07, 2.1484e-07, 2.2801e-06,\n",
      "        1.6338e-06, 6.4732e-07, 8.7689e-07, 2.8727e-07, 2.3371e-07, 4.1931e-07,\n",
      "        2.6187e-07, 6.2523e-04, 1.6849e-03, 6.9454e-05, 3.8416e-04, 5.3380e-06,\n",
      "        6.4328e-06, 8.9802e-04, 1.5245e-05, 3.3032e-06, 1.1725e-06, 4.8914e-07,\n",
      "        7.0097e-07, 5.7670e-07, 2.1551e-06, 2.7529e-07, 1.3300e-06, 2.1826e-07,\n",
      "        1.4188e-06, 3.7434e-05, 7.1011e-06, 1.0582e-06, 5.4379e-07, 3.5360e-06,\n",
      "        8.7099e-05, 3.8685e-06, 5.5376e-07, 1.0737e-06, 9.2932e-07, 5.6239e-06,\n",
      "        9.7341e-06, 4.9480e-07, 6.8882e-06, 9.2838e-07, 1.9575e-06, 5.7295e-05,\n",
      "        2.8308e-04, 8.2990e-06, 9.6670e-06, 1.3866e-06, 2.9672e-06, 1.2098e-06,\n",
      "        1.3789e-04, 9.0221e-05, 2.2683e-06, 7.2420e-06, 7.5067e-07, 8.8816e-07,\n",
      "        3.9409e-07, 4.6532e-05, 1.0469e-05, 1.3908e-05, 2.1419e-06, 3.8094e-04,\n",
      "        1.0101e-05, 1.9803e-06, 5.4123e-07, 5.2672e-05, 6.4867e-06, 1.2587e-06,\n",
      "        6.8020e-07, 2.9875e-06, 9.3904e-06, 1.9674e-06, 2.5251e-06, 7.4646e-06,\n",
      "        1.6778e-05, 2.1208e-06, 2.6151e-06, 7.9086e-07, 6.4798e-06, 5.5748e-07,\n",
      "        1.0559e-03, 1.7219e-03, 6.9625e-04, 4.5965e-06, 3.5958e-05, 3.7970e-05,\n",
      "        6.6005e-05, 2.0491e-05, 9.8787e-04, 1.3608e-03, 8.0533e-04, 6.1908e-06,\n",
      "        2.3569e-06, 1.3784e-04, 2.3030e-05, 5.0664e-06, 1.2621e-06, 8.5598e-06,\n",
      "        6.7036e-06, 3.7163e-06, 3.6972e-06, 6.0195e-07, 2.3252e-05, 2.4614e-06,\n",
      "        3.0765e-06, 2.0054e-05, 6.8955e-03, 8.0045e-04, 9.2791e-04, 3.4023e-05,\n",
      "        9.4898e-06, 1.0392e-05, 3.7859e-06, 4.5196e-06, 4.6594e-05, 2.1199e-03,\n",
      "        7.9075e-01, 8.9777e-02, 1.1508e-03, 2.6814e-02, 4.8139e-06, 1.8559e-04,\n",
      "        2.3389e-05, 3.1445e-05, 1.9670e-05, 2.0621e-05, 1.0652e-06, 6.3979e-04,\n",
      "        3.6103e-02, 1.2006e-05, 3.6789e-05, 8.5825e-05, 3.0814e-04, 5.4408e-06,\n",
      "        8.2216e-06, 4.1573e-05, 3.2707e-05, 2.2788e-02, 1.1195e-04, 4.1722e-05,\n",
      "        4.9956e-05, 1.3285e-03, 6.1223e-06, 2.1842e-05, 8.2636e-07, 6.0375e-05,\n",
      "        6.2312e-06, 2.9731e-05, 2.1508e-06, 2.2650e-05, 2.0419e-05, 1.1749e-05,\n",
      "        2.2505e-06, 2.4240e-06, 1.7285e-05, 2.9559e-06, 2.6463e-06, 1.9448e-06,\n",
      "        4.1384e-07, 7.8102e-07, 7.8781e-07, 8.5714e-07, 1.0265e-06, 2.6949e-07,\n",
      "        3.4574e-06, 2.1444e-06, 9.5581e-08, 9.3096e-07, 8.7138e-06, 1.8040e-06,\n",
      "        8.2589e-07, 2.0439e-06, 2.8276e-06, 3.9820e-07, 7.1246e-07, 3.5476e-06,\n",
      "        2.0526e-06, 1.2684e-07, 4.2869e-07, 3.3442e-07, 3.7553e-07, 6.0095e-07,\n",
      "        8.6192e-07, 3.0218e-06, 1.6219e-06, 4.7091e-06, 3.6432e-06, 2.1119e-06,\n",
      "        2.1964e-05, 1.6725e-04, 9.6179e-04, 1.5189e-04, 1.3581e-05, 2.0585e-05,\n",
      "        1.9302e-06, 2.7990e-06, 2.1240e-05, 1.4275e-06, 1.5874e-06, 1.3770e-05,\n",
      "        2.0084e-06, 4.4016e-07, 2.7445e-07, 6.9985e-06, 3.8670e-06, 1.7379e-06,\n",
      "        1.2044e-05, 5.0550e-07, 3.2866e-07, 1.7548e-07, 3.1725e-07, 1.9597e-06,\n",
      "        5.8910e-07, 2.3590e-05, 2.9364e-05, 2.7382e-05, 7.6339e-05, 3.5155e-05,\n",
      "        4.0811e-07, 1.7616e-04, 9.8992e-06, 5.6549e-06, 2.7965e-07, 4.8897e-07,\n",
      "        1.8481e-07, 1.4214e-06, 5.5926e-06, 1.1438e-06, 5.6345e-07, 2.0752e-06,\n",
      "        1.0984e-06, 9.9921e-06, 9.6116e-07, 3.2368e-07, 5.2384e-08, 2.1463e-05,\n",
      "        9.5670e-07, 7.8798e-07, 3.7398e-06, 8.6038e-07, 2.1976e-06, 7.1789e-06,\n",
      "        5.1570e-06, 1.4158e-07, 1.1406e-08, 6.1676e-06, 2.3070e-06, 6.8954e-07,\n",
      "        5.9813e-07, 1.8327e-06, 6.3302e-07, 3.1002e-07, 3.6046e-07, 2.3218e-07,\n",
      "        8.3247e-07, 3.5204e-07, 4.1459e-06, 8.2421e-07, 1.9154e-07, 5.0261e-06,\n",
      "        2.0431e-06, 4.5651e-07, 6.2586e-07, 2.6884e-05, 2.7206e-07, 1.7650e-07,\n",
      "        1.9072e-06, 4.0348e-05, 2.4796e-07, 1.2251e-06, 3.9584e-06, 1.8093e-06,\n",
      "        8.2174e-07, 7.2891e-07, 5.8878e-07, 8.4455e-06, 5.3081e-06, 8.3304e-06,\n",
      "        3.7967e-06, 8.2081e-07, 6.8127e-06, 8.2059e-08, 4.3756e-08, 4.3138e-06,\n",
      "        2.5152e-06, 1.8838e-05, 2.4712e-05, 4.7968e-05, 2.5948e-06, 1.5344e-06,\n",
      "        4.1229e-07, 1.3267e-06, 2.1068e-06, 1.0748e-05, 1.1018e-06, 2.0203e-06,\n",
      "        5.7446e-07, 1.8159e-05, 2.9369e-06, 9.6544e-07, 3.7443e-06, 1.4676e-06,\n",
      "        6.5774e-06, 1.3459e-05, 4.7757e-06, 2.8846e-07, 2.4922e-06, 6.5005e-07,\n",
      "        5.6079e-05, 2.7314e-07, 4.4330e-06, 1.0049e-06, 4.0271e-07, 2.1105e-06,\n",
      "        6.0487e-06, 7.8023e-06, 1.4044e-06, 5.1699e-06, 1.2897e-06, 1.2795e-06,\n",
      "        8.4733e-06, 2.7800e-05, 1.0383e-06, 8.8511e-07, 3.9553e-07, 1.1574e-07,\n",
      "        2.5891e-06, 6.6103e-05, 6.6159e-05, 5.0686e-06, 7.0814e-06, 2.9322e-06,\n",
      "        4.6838e-07, 9.0653e-07, 3.2024e-06, 2.9487e-06, 1.1927e-05, 5.0227e-06,\n",
      "        2.2824e-07, 2.5799e-06, 4.0439e-07, 2.4521e-06, 4.0358e-06, 3.4257e-06,\n",
      "        1.4341e-06, 7.5828e-07, 1.9327e-05, 8.9163e-06, 5.6116e-07, 2.5362e-06,\n",
      "        6.8007e-07, 7.2112e-07, 1.0026e-05, 8.0647e-07, 2.2280e-06, 1.5791e-06,\n",
      "        3.4686e-07, 7.1064e-06, 5.9074e-08, 8.1284e-06, 1.2970e-05, 6.3947e-07,\n",
      "        5.2060e-06, 5.0383e-06, 1.8350e-06, 2.2323e-06, 1.2868e-05, 1.3491e-07,\n",
      "        3.8567e-06, 2.8170e-06, 4.5717e-06, 9.5979e-07, 2.5461e-07, 1.8294e-05,\n",
      "        1.7909e-06, 8.1132e-07, 2.6575e-06, 3.6137e-06, 9.0953e-07, 7.9028e-06,\n",
      "        1.2269e-05, 2.2743e-06, 4.7570e-07, 6.3952e-07, 4.0078e-07, 8.7949e-07,\n",
      "        3.9191e-06, 1.5274e-06, 1.6246e-05, 2.8533e-07, 1.9036e-06, 7.0725e-07,\n",
      "        4.3026e-06, 4.2517e-06, 9.2212e-07, 7.9498e-05, 1.1947e-06, 1.5078e-05,\n",
      "        5.8433e-07, 6.7978e-06, 8.5376e-06, 5.1028e-06, 8.6043e-06, 6.6312e-06,\n",
      "        6.2782e-06, 3.6477e-08, 7.0228e-07, 1.4556e-06, 2.4324e-07, 3.7730e-06,\n",
      "        6.0750e-05, 7.4948e-07, 7.8266e-06, 6.0281e-07, 6.0922e-06, 4.5692e-06,\n",
      "        4.4497e-06, 3.0656e-06, 1.8064e-05, 9.0479e-07, 2.1464e-06, 1.3542e-06,\n",
      "        8.5269e-07, 2.3092e-07, 1.6689e-06, 4.0973e-06, 4.1579e-06, 3.3181e-07,\n",
      "        8.5929e-07, 1.2330e-07, 1.0141e-05, 7.0571e-06, 1.0812e-05, 3.2921e-07,\n",
      "        3.4908e-07, 4.9792e-06, 2.8970e-06, 5.2635e-06, 3.7016e-06, 3.7682e-07,\n",
      "        7.9726e-07, 8.4888e-07, 2.4930e-06, 9.0410e-06, 8.1054e-07, 2.7339e-06,\n",
      "        6.5084e-07, 3.4719e-06, 3.2679e-06, 1.9106e-06, 8.5861e-07, 3.3026e-06,\n",
      "        1.1659e-05, 3.3659e-07, 7.8709e-06, 9.8247e-07, 1.0332e-06, 2.7254e-07,\n",
      "        3.8083e-06, 4.1606e-06, 9.4150e-07, 5.5875e-07, 1.2859e-06, 1.5465e-06,\n",
      "        1.4889e-05, 1.5103e-05, 3.3819e-06, 2.2119e-07, 1.5914e-06, 8.8787e-06,\n",
      "        2.4240e-07, 1.5033e-06, 2.5457e-06, 2.1461e-06, 1.4840e-06, 1.9527e-06,\n",
      "        3.8199e-06, 2.9184e-06, 2.8791e-06, 1.0475e-05, 1.1273e-05, 3.4657e-06,\n",
      "        7.6517e-07, 4.5267e-06, 2.5560e-06, 4.7290e-07, 6.1192e-06, 7.6278e-06,\n",
      "        2.7460e-06, 4.8024e-05, 9.0722e-06, 1.6833e-06, 4.0417e-07, 9.8634e-06,\n",
      "        2.8301e-06, 6.1098e-06, 3.1091e-06, 2.6466e-06, 1.0827e-06, 6.8062e-06,\n",
      "        1.3499e-06, 3.7492e-06, 6.6094e-06, 6.2553e-07, 6.8024e-06, 8.7125e-06,\n",
      "        9.6218e-07, 5.4040e-07, 4.5800e-07, 9.2340e-07, 4.0953e-06, 5.7332e-05,\n",
      "        3.2771e-07, 2.6067e-06, 7.1574e-07, 4.2474e-05, 4.1748e-06, 2.1324e-06,\n",
      "        4.3446e-07, 8.0309e-07, 1.4551e-05, 1.7981e-07, 1.1110e-05, 6.9138e-07,\n",
      "        4.8923e-06, 2.2695e-06, 1.2242e-06, 3.0489e-06, 1.2227e-06, 1.4236e-06,\n",
      "        1.1032e-06, 7.4258e-06, 1.7022e-05, 3.3424e-07, 4.8544e-05, 3.7093e-06,\n",
      "        6.9563e-07, 1.9777e-06, 2.6095e-05, 1.5742e-06, 5.0231e-07, 2.2237e-06,\n",
      "        4.3282e-06, 1.7009e-06, 2.5069e-06, 8.1778e-07, 9.1566e-06, 8.1989e-07,\n",
      "        1.9383e-06, 3.2976e-07, 1.9793e-05, 1.7082e-06, 2.1021e-06, 1.3967e-06,\n",
      "        3.9680e-07, 1.4332e-06, 9.6623e-07, 8.1888e-06, 2.5255e-05, 1.8636e-06,\n",
      "        2.2666e-07, 7.4045e-06, 1.0780e-06, 7.4960e-08, 7.5968e-07, 1.0533e-06,\n",
      "        3.0060e-06, 5.2553e-06, 2.9849e-06, 1.3047e-05, 5.2369e-06, 7.1414e-07,\n",
      "        1.5675e-06, 3.0549e-07, 1.0565e-05, 2.4076e-07, 2.4306e-06, 3.8913e-05,\n",
      "        3.2640e-06, 4.8866e-06, 4.2362e-05, 5.4277e-06, 3.8888e-07, 2.8408e-06,\n",
      "        1.4495e-07, 1.0083e-06, 1.9949e-05, 7.5649e-07, 3.2635e-06, 6.4188e-06,\n",
      "        6.5934e-07, 3.6784e-06, 6.4681e-08, 5.6625e-06, 1.5574e-06, 1.2945e-06,\n",
      "        8.9311e-06, 2.7552e-07, 5.3127e-07, 2.5272e-06, 1.0859e-05, 1.3410e-07,\n",
      "        1.2219e-05, 5.2351e-07, 6.3139e-06, 5.9305e-06, 1.1962e-05, 1.2153e-05,\n",
      "        9.1582e-06, 7.0804e-06, 9.5391e-06, 9.2867e-06, 2.9846e-06, 7.0897e-07,\n",
      "        1.6957e-05, 3.4903e-07, 2.2419e-06, 5.9789e-07, 4.6346e-06, 2.6257e-05,\n",
      "        3.6456e-07, 1.3889e-06, 3.8852e-06, 1.6066e-05, 2.4891e-06, 1.3599e-06,\n",
      "        1.2625e-04, 1.6637e-05, 2.0075e-06, 1.1649e-06, 6.5717e-06, 6.6233e-06,\n",
      "        1.1489e-06, 8.3567e-06, 9.8957e-07, 2.4661e-06, 4.5563e-06, 1.6137e-07,\n",
      "        3.2623e-06, 3.6379e-06, 1.4746e-05, 6.1802e-06, 2.9031e-06, 2.1082e-06,\n",
      "        3.4243e-06, 9.4035e-06, 1.6009e-06, 5.9932e-06, 5.6744e-07, 2.1849e-06,\n",
      "        8.7431e-06, 2.1308e-06, 3.2570e-06, 1.0882e-06, 7.3824e-07, 1.0525e-05,\n",
      "        1.1866e-06, 1.2748e-06, 5.1019e-07, 6.0995e-07, 1.2268e-06, 6.2253e-07,\n",
      "        2.4413e-06, 7.6215e-05, 2.7225e-06, 6.8404e-06, 4.7962e-06, 3.3952e-06,\n",
      "        1.1382e-05, 3.8570e-05, 4.7635e-07, 1.5263e-06, 1.1976e-05, 1.2755e-06,\n",
      "        3.8758e-06, 2.8976e-06, 7.1911e-07, 4.2639e-07, 1.3766e-06, 5.1301e-07,\n",
      "        2.2904e-06, 3.5403e-06, 8.2404e-06, 1.0370e-06, 1.3660e-05, 1.2343e-05,\n",
      "        6.2337e-06, 1.6666e-07, 9.2024e-07, 8.6720e-06, 7.5684e-07, 3.8661e-06,\n",
      "        6.9464e-07, 2.9929e-06, 5.5253e-06, 9.4538e-06, 1.9011e-05, 8.5914e-07,\n",
      "        2.2919e-06, 2.6032e-06, 2.2691e-06, 1.3483e-06, 2.6164e-05, 8.3757e-06,\n",
      "        9.5735e-07, 1.3525e-06, 1.1828e-06, 1.1873e-05, 3.8277e-06, 1.5074e-05,\n",
      "        2.3717e-04, 9.7185e-07, 6.2271e-07, 4.7415e-06, 5.7593e-07, 7.6723e-07,\n",
      "        7.1816e-07, 2.1123e-06, 4.9254e-07, 5.0237e-06, 3.8063e-06, 3.0928e-07,\n",
      "        3.8864e-07, 7.3012e-07, 3.1141e-06, 1.1506e-06, 6.2043e-06, 2.6409e-06,\n",
      "        8.8753e-06, 3.6506e-06, 2.7894e-06, 3.7435e-07, 4.1008e-08, 8.0918e-07,\n",
      "        4.2847e-05, 5.7216e-07, 5.1684e-06, 1.6785e-05, 2.9335e-06, 1.0346e-06,\n",
      "        3.3971e-06, 2.0064e-06, 2.8491e-07, 1.0270e-06, 2.2705e-06, 1.3247e-07,\n",
      "        9.9282e-08, 8.2227e-07, 3.2815e-06, 5.7043e-06, 1.3592e-05, 6.6944e-07,\n",
      "        1.0551e-06, 2.3346e-07, 4.1828e-07, 1.1512e-06, 6.3236e-06, 5.4074e-06,\n",
      "        6.1272e-06, 9.9914e-07, 5.5173e-05, 1.4881e-06, 4.9384e-06, 1.8112e-06,\n",
      "        2.6437e-07, 2.9367e-06, 8.1664e-07, 2.2008e-06, 2.8713e-06, 1.4974e-05,\n",
      "        2.5712e-05, 1.1209e-06, 1.8267e-06, 1.7346e-06, 2.3125e-06, 3.4534e-07,\n",
      "        1.4166e-06, 6.4804e-07, 3.6050e-07, 1.0220e-05, 6.0145e-07, 2.6028e-06,\n",
      "        1.3053e-06, 1.9744e-06, 1.4412e-06, 1.2712e-06, 2.6227e-07, 1.5015e-05,\n",
      "        1.3013e-06, 5.2421e-07, 1.3214e-06, 1.6851e-07, 5.4782e-06, 3.5458e-06,\n",
      "        4.3987e-06, 1.1126e-05, 3.0054e-06, 5.8080e-06, 8.1585e-06, 3.9473e-06,\n",
      "        2.9968e-06, 4.8989e-06, 1.6989e-06, 8.4423e-07, 1.2972e-06, 3.4963e-06,\n",
      "        1.0539e-05, 4.9402e-06, 1.4046e-06, 3.1675e-06, 1.4457e-06, 2.5440e-06,\n",
      "        1.3496e-06, 6.1341e-07, 2.2218e-06, 3.2056e-05, 1.8561e-06, 8.7489e-06,\n",
      "        2.2867e-07, 1.5547e-06, 8.8639e-07, 4.9682e-06, 2.5424e-07, 5.9241e-07,\n",
      "        1.6910e-05, 2.9081e-07, 3.1906e-05, 2.5072e-06, 1.2655e-06, 1.6682e-05,\n",
      "        8.2988e-07, 2.3648e-07, 1.2269e-06, 1.3952e-05, 4.3819e-06, 4.1544e-06,\n",
      "        2.3152e-06, 6.5655e-07, 1.0795e-06, 2.5352e-06, 7.8109e-07, 4.9881e-07,\n",
      "        3.0899e-07, 3.5854e-06, 2.2337e-06, 1.2389e-05, 6.5273e-06, 2.1694e-06,\n",
      "        3.0996e-06, 6.5137e-06, 2.5407e-06, 7.1614e-08, 4.0808e-07, 3.1562e-06,\n",
      "        3.8456e-06, 4.2661e-07, 3.3610e-06, 3.2956e-06], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(258, device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib\n",
    "url, filename = (\"https://github.com/pytorch/hub/raw/master/dog.jpg\", \"dog.jpg\")\n",
    "try: urllib.URLopener().retrieve(url, filename)\n",
    "except: urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "# sample execution (requires torchvision)\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "input_image = Image.open(filename)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "# move the input and model to GPU for speed if available\n",
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    model.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "# Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
    "print(output[0])\n",
    "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
    "print(torch.nn.functional.softmax(output[0], dim=0))\n",
    "\n",
    "result = torch.nn.functional.softmax(output[0], dim=0)\n",
    "\n",
    "result.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.6715e-01, -7.1970e-01, -1.1477e+00, -1.4235e+00, -2.3382e+00,\n",
      "         1.3198e+00, -8.5561e-01,  1.9753e+00,  4.7764e+00, -1.5662e-01,\n",
      "        -9.2236e-01, -6.4763e-01, -1.4888e+00, -9.3758e-01, -3.3264e-01,\n",
      "        -1.2148e+00, -1.0260e+00,  1.5018e+00,  3.0635e-01, -7.9825e-01,\n",
      "        -1.4174e+00, -7.2353e-01, -1.8555e+00, -4.3315e-02, -2.2541e+00,\n",
      "        -5.4571e-01,  1.2344e-01,  6.8431e-01, -7.2438e-01,  3.0649e+00,\n",
      "        -3.7269e-01,  1.7250e-01,  1.4965e+00, -1.8406e+00, -1.1434e-01,\n",
      "        -9.1618e-01, -1.4046e+00, -9.8438e-01, -1.4462e-01, -5.3998e-01,\n",
      "        -1.5295e+00, -1.9589e+00, -2.4135e+00, -2.1158e+00, -1.2151e-01,\n",
      "        -9.3840e-01,  6.4887e-01, -7.0536e-01, -3.1816e+00, -1.2064e+00,\n",
      "        -1.2384e+00, -1.4129e+00,  5.9586e-01, -2.7741e+00, -5.9331e-01,\n",
      "        -8.8087e-01, -7.7742e-01, -1.8902e-01, -5.2709e-01, -1.3785e+00,\n",
      "         1.3683e+00, -1.4733e+00, -2.3232e+00, -2.6685e+00, -1.2786e+00,\n",
      "        -1.3968e+00, -3.7588e-01, -2.3240e+00, -1.2900e+00, -3.1433e+00,\n",
      "        -1.2508e+00,  3.4481e-01, -2.1857e+00, -7.6116e-01, -1.1072e+00,\n",
      "        -5.4388e-01, -1.4990e+00, -1.0113e+00,  2.7084e+00,  1.6177e+00,\n",
      "        -6.2918e-01,  1.7059e-01,  5.6959e-01, -8.3642e-01,  5.1573e-01,\n",
      "        -3.5493e-01,  2.9007e-01, -1.5159e+00, -1.5285e+00,  1.1817e+00,\n",
      "        -1.7718e+00, -1.7817e+00, -3.0281e+00, -1.5648e+00, -1.4278e+00,\n",
      "        -2.9525e+00, -1.6395e+00, -1.8020e+00, -2.6962e+00, -7.0659e-01,\n",
      "         8.7182e-01, -2.5566e+00,  2.0441e-01, -2.8165e+00,  4.1807e+00,\n",
      "        -1.2253e+00,  1.8673e+00, -1.0163e+00,  6.9645e-01, -3.4444e+00,\n",
      "         6.8967e-02, -1.7000e+00,  1.0739e+00,  1.1161e-01,  5.3168e-01,\n",
      "         1.6918e-01, -2.1360e+00, -6.6472e-01, -5.2803e-01, -2.0712e-01,\n",
      "        -1.8586e+00, -6.4501e-01,  3.4128e-01, -5.7678e-01, -3.4810e-02,\n",
      "        -7.7270e-01,  3.4117e-01, -4.3863e-01, -2.8679e+00,  1.8149e-02,\n",
      "        -5.2458e-01, -1.9694e+00, -4.0739e-01, -2.6458e+00, -2.5536e+00,\n",
      "        -2.1011e+00, -4.7708e-01, -1.6839e+00, -2.6292e+00, -1.5264e+00,\n",
      "        -2.7248e+00, -2.0679e+00, -2.5157e+00, -1.5359e-01, -4.8687e-01,\n",
      "        -1.4127e+00, -1.1092e+00, -2.2251e+00, -2.4315e+00, -1.8469e+00,\n",
      "        -2.3177e+00,  5.4603e+00,  6.4517e+00,  3.2629e+00,  4.9733e+00,\n",
      "         6.9705e-01,  8.8361e-01,  5.8224e+00,  1.7464e+00,  2.1710e-01,\n",
      "        -8.1869e-01, -1.6929e+00, -1.3331e+00, -1.5282e+00, -2.0995e-01,\n",
      "        -2.2677e+00, -6.9262e-01, -2.4999e+00, -6.2800e-01,  2.6448e+00,\n",
      "         9.8245e-01, -9.2124e-01, -1.5870e+00,  2.8520e-01,  3.4893e+00,\n",
      "         3.7509e-01, -1.5688e+00, -9.0667e-01, -1.0511e+00,  7.4924e-01,\n",
      "         1.2978e+00, -1.6814e+00,  9.5201e-01, -1.0521e+00, -3.0612e-01,\n",
      "         3.0704e+00,  4.6679e+00,  1.1383e+00,  1.2909e+00, -6.5094e-01,\n",
      "         1.0984e-01, -7.8735e-01,  3.9486e+00,  3.5245e+00, -1.5877e-01,\n",
      "         1.0021e+00, -1.2646e+00, -1.0964e+00, -1.9090e+00,  2.8624e+00,\n",
      "         1.3707e+00,  1.6547e+00, -2.1610e-01,  4.9648e+00,  1.3348e+00,\n",
      "        -2.9454e-01, -1.5917e+00,  2.9863e+00,  8.9196e-01, -7.4773e-01,\n",
      "        -1.3632e+00,  1.1665e-01,  1.2619e+00, -3.0106e-01, -5.1495e-02,\n",
      "         1.0324e+00,  1.8423e+00, -2.2598e-01, -1.6475e-02, -1.2124e+00,\n",
      "         8.9089e-01, -1.5621e+00,  5.9844e+00,  6.4734e+00,  5.5679e+00,\n",
      "         5.4751e-01,  2.6045e+00,  2.6590e+00,  3.2119e+00,  2.0422e+00,\n",
      "         5.9178e+00,  6.2380e+00,  5.7135e+00,  8.4527e-01, -1.2045e-01,\n",
      "         3.9483e+00,  2.1590e+00,  6.4484e-01, -7.4500e-01,  1.1693e+00,\n",
      "         9.2486e-01,  3.3494e-01,  3.2979e-01, -1.4854e+00,  2.1686e+00,\n",
      "        -7.7058e-02,  1.4600e-01,  2.0207e+00,  7.8608e+00,  5.7074e+00,\n",
      "         5.8551e+00,  2.5493e+00,  1.2724e+00,  1.3632e+00,  3.5348e-01,\n",
      "         5.3063e-01,  2.8637e+00,  6.6813e+00,  1.2603e+01,  1.0427e+01,\n",
      "         6.0704e+00,  9.2189e+00,  5.9372e-01,  4.2457e+00,  2.1745e+00,\n",
      "         2.4705e+00,  2.0013e+00,  2.0485e+00, -9.1465e-01,  5.4834e+00,\n",
      "         9.5163e+00,  1.5076e+00,  2.6274e+00,  3.4745e+00,  4.7528e+00,\n",
      "         7.1613e-01,  1.1290e+00,  2.7497e+00,  2.5098e+00,  9.0562e+00,\n",
      "         3.7402e+00,  2.7532e+00,  2.9333e+00,  6.2140e+00,  8.3414e-01,\n",
      "         2.1061e+00, -1.1685e+00,  3.1228e+00,  8.5177e-01,  2.4144e+00,\n",
      "        -2.1198e-01,  2.1424e+00,  2.0387e+00,  1.4860e+00, -1.6665e-01,\n",
      "        -9.2356e-02,  1.8721e+00,  1.0602e-01, -4.6454e-03, -3.1264e-01,\n",
      "        -1.8601e+00, -1.2249e+00, -1.2163e+00, -1.1319e+00, -9.5160e-01,\n",
      "        -2.2890e+00,  2.6274e-01, -2.1494e-01, -3.3256e+00, -1.0493e+00,\n",
      "         1.1871e+00, -3.8781e-01, -1.1691e+00, -2.6291e-01,  6.1630e-02,\n",
      "        -1.8986e+00, -1.3168e+00,  2.8846e-01, -2.5870e-01, -3.0426e+00,\n",
      "        -1.8248e+00, -2.0732e+00, -1.9572e+00, -1.4870e+00, -1.1264e+00,\n",
      "         1.2805e-01, -4.9419e-01,  5.7170e-01,  3.1508e-01, -2.3021e-01,\n",
      "         2.1116e+00,  4.1417e+00,  5.8910e+00,  4.0454e+00,  1.6309e+00,\n",
      "         2.0468e+00, -3.2016e-01,  5.1478e-02,  2.0781e+00, -6.2190e-01,\n",
      "        -5.1572e-01,  1.6447e+00, -2.8046e-01, -1.7984e+00, -2.2708e+00,\n",
      "         9.6790e-01,  3.7468e-01, -4.2509e-01,  1.5108e+00, -1.6600e+00,\n",
      "        -2.0905e+00, -2.7180e+00, -2.1259e+00, -3.0499e-01, -1.5070e+00,\n",
      "         2.1830e+00,  2.4020e+00,  2.3321e+00,  3.3574e+00,  2.5820e+00,\n",
      "        -1.8740e+00,  4.1936e+00,  1.3147e+00,  7.5473e-01, -2.2520e+00,\n",
      "        -1.6932e+00, -2.6662e+00, -6.2615e-01,  7.4366e-01, -8.4340e-01,\n",
      "        -1.5515e+00, -2.4772e-01, -8.8397e-01,  1.3240e+00, -1.0174e+00,\n",
      "        -2.1058e+00, -3.9270e+00,  2.0885e+00, -1.0221e+00, -1.2161e+00,\n",
      "         3.4124e-01, -1.1282e+00, -1.9041e-01,  9.9335e-01,  6.6256e-01,\n",
      "        -2.9327e+00, -5.4514e+00,  8.4152e-01, -1.4183e-01, -1.3495e+00,\n",
      "        -1.4917e+00, -3.7201e-01, -1.4351e+00, -2.1489e+00, -1.9982e+00,\n",
      "        -2.4381e+00, -1.1612e+00, -2.0218e+00,  4.4432e-01, -1.1711e+00,\n",
      "        -2.6305e+00,  6.3685e-01, -2.6331e-01, -1.7619e+00, -1.4464e+00,\n",
      "         2.3137e+00, -2.2795e+00, -2.7122e+00, -3.3218e-01,  2.7197e+00,\n",
      "        -2.3723e+00, -7.7473e-01,  3.9806e-01, -3.8488e-01, -1.1741e+00,\n",
      "        -1.2940e+00, -1.5075e+00,  1.1558e+00,  6.9144e-01,  1.1421e+00,\n",
      "         3.5634e-01, -1.1753e+00,  9.4099e-01, -3.4781e+00, -4.1069e+00,\n",
      "         4.8404e-01, -5.5461e-02,  1.9581e+00,  2.2295e+00,  2.8928e+00,\n",
      "        -2.4266e-02, -5.4963e-01, -1.8638e+00, -6.9512e-01, -2.3262e-01,\n",
      "         1.3969e+00, -8.8082e-01, -2.7454e-01, -1.5321e+00,  1.9214e+00,\n",
      "         9.9576e-02, -1.0130e+00,  3.4243e-01, -5.9417e-01,  9.0585e-01,\n",
      "         1.6219e+00,  5.8575e-01, -2.2210e+00, -6.4647e-02, -1.4085e+00,\n",
      "         3.0490e+00, -2.2756e+00,  5.1129e-01, -9.7291e-01, -1.8873e+00,\n",
      "        -2.3089e-01,  8.2205e-01,  1.0766e+00, -6.3817e-01,  6.6505e-01,\n",
      "        -7.2338e-01, -7.3132e-01,  1.1591e+00,  2.3472e+00, -9.4020e-01,\n",
      "        -1.0998e+00, -1.9053e+00, -3.1342e+00, -2.6468e-02,  3.2134e+00,\n",
      "         3.2143e+00,  6.4527e-01,  9.7968e-01,  9.7945e-02, -1.7363e+00,\n",
      "        -1.0759e+00,  1.8611e-01,  1.0358e-01,  1.5010e+00,  6.3617e-01,\n",
      "        -2.4552e+00, -3.0039e-02, -1.8832e+00, -8.0862e-02,  4.1741e-01,\n",
      "         2.5351e-01, -6.1729e-01, -1.2545e+00,  1.9837e+00,  1.2101e+00,\n",
      "        -1.5555e+00, -4.7125e-02, -1.3633e+00, -1.3047e+00,  1.3274e+00,\n",
      "        -1.1929e+00, -1.7667e-01, -5.2095e-01, -2.0366e+00,  9.8320e-01,\n",
      "        -3.8068e+00,  1.1176e+00,  1.5848e+00, -1.4249e+00,  6.7201e-01,\n",
      "         6.3927e-01, -3.7073e-01, -1.7475e-01,  1.5769e+00, -2.9809e+00,\n",
      "         3.7202e-01,  5.7863e-02,  5.4210e-01, -1.0188e+00, -2.3458e+00,\n",
      "         1.9288e+00, -3.9506e-01, -1.1869e+00, -3.9326e-04,  3.0694e-01,\n",
      "        -1.0726e+00,  1.0894e+00,  1.5293e+00, -1.5613e-01, -1.7208e+00,\n",
      "        -1.4248e+00, -1.8921e+00, -1.1062e+00,  3.8807e-01, -5.5422e-01,\n",
      "         1.8101e+00, -2.2319e+00, -3.3404e-01, -1.3242e+00,  4.8143e-01,\n",
      "         4.6952e-01, -1.0589e+00,  3.3979e+00, -7.9990e-01,  1.7354e+00,\n",
      "        -1.5151e+00,  9.3880e-01,  1.1667e+00,  6.5200e-01,  1.1745e+00,\n",
      "         9.1399e-01,  8.5929e-01, -4.2889e+00, -1.3312e+00, -6.0239e-01,\n",
      "        -2.3915e+00,  3.5007e-01,  3.1290e+00, -1.2662e+00,  1.0797e+00,\n",
      "        -1.4840e+00,  8.2921e-01,  5.4154e-01,  5.1505e-01,  1.4244e-01,\n",
      "         1.9161e+00, -1.0778e+00, -2.1398e-01, -6.7459e-01, -1.1371e+00,\n",
      "        -2.4435e+00, -4.6562e-01,  4.3253e-01,  4.4721e-01, -2.0810e+00,\n",
      "        -1.1294e+00, -3.0710e+00,  1.3388e+00,  9.7624e-01,  1.4029e+00,\n",
      "        -2.0888e+00, -2.0302e+00,  6.2748e-01,  8.5878e-02,  6.8300e-01,\n",
      "         3.3098e-01, -1.9538e+00, -1.2044e+00, -1.1416e+00, -6.4296e-02,\n",
      "         1.2240e+00, -1.1878e+00,  2.7924e-02, -1.4073e+00,  2.6692e-01,\n",
      "         2.0636e-01, -3.3039e-01, -1.1302e+00,  2.1691e-01,  1.4783e+00,\n",
      "        -2.0667e+00,  1.0854e+00, -9.9548e-01, -9.4511e-01, -2.2778e+00,\n",
      "         3.5939e-01,  4.4787e-01, -1.0381e+00, -1.5599e+00, -7.2636e-01,\n",
      "        -5.4177e-01,  1.7228e+00,  1.7371e+00,  2.4064e-01, -2.4865e+00,\n",
      "        -5.1316e-01,  1.2059e+00, -2.3950e+00, -5.7015e-01, -4.3394e-02,\n",
      "        -2.1415e-01, -5.8304e-01, -3.0858e-01,  3.6244e-01,  9.3229e-02,\n",
      "         7.9670e-02,  1.3712e+00,  1.4446e+00,  2.6511e-01, -1.2455e+00,\n",
      "         5.3220e-01, -3.9367e-02, -1.7267e+00,  8.3364e-01,  1.0540e+00,\n",
      "         3.2333e-02,  2.8939e+00,  1.2274e+00, -4.5704e-01, -1.8837e+00,\n",
      "         1.3110e+00,  6.2529e-02,  8.3211e-01,  1.5654e-01, -4.5221e-03,\n",
      "        -8.9832e-01,  9.4004e-01, -6.7775e-01,  3.4375e-01,  9.1070e-01,\n",
      "        -1.4470e+00,  9.3948e-01,  1.1870e+00, -1.0163e+00, -1.5932e+00,\n",
      "        -1.7587e+00, -1.0575e+00,  4.3204e-01,  3.0711e+00, -2.0934e+00,\n",
      "        -1.9722e-02, -1.3122e+00,  2.7711e+00,  4.5127e-01, -2.2057e-01,\n",
      "        -1.8114e+00, -1.1971e+00,  1.6999e+00, -2.6937e+00,  1.4300e+00,\n",
      "        -1.3469e+00,  6.0987e-01, -1.5825e-01, -7.7549e-01,  1.3699e-01,\n",
      "        -7.7675e-01, -6.2460e-01, -8.7960e-01,  1.0272e+00,  1.8567e+00,\n",
      "        -2.0737e+00,  2.9047e+00,  3.3306e-01, -1.3407e+00, -2.9588e-01,\n",
      "         2.2839e+00, -5.2406e-01, -1.6663e+00, -1.7864e-01,  4.8736e-01,\n",
      "        -4.4662e-01, -5.8747e-02, -1.1790e+00,  1.2367e+00, -1.1764e+00,\n",
      "        -3.1599e-01, -2.0872e+00,  2.0075e+00, -4.4235e-01, -2.3487e-01,\n",
      "        -6.4370e-01, -1.9021e+00, -6.1788e-01, -1.0122e+00,  1.1250e+00,\n",
      "         2.2512e+00, -3.5527e-01, -2.4621e+00,  1.0243e+00, -9.0271e-01,\n",
      "        -3.5686e+00, -1.2527e+00, -9.2588e-01,  1.2281e-01,  6.8144e-01,\n",
      "         1.1578e-01,  1.5908e+00,  6.7794e-01, -1.3145e+00, -5.2830e-01,\n",
      "        -2.1636e+00,  1.3797e+00, -2.4018e+00, -8.9641e-02,  2.6835e+00,\n",
      "         2.0517e-01,  6.0871e-01,  2.7685e+00,  7.1373e-01, -1.9223e+00,\n",
      "         6.6284e-02, -2.9092e+00, -9.6957e-01,  2.0154e+00, -1.2569e+00,\n",
      "         2.0502e-01,  8.8144e-01, -1.3943e+00,  3.2469e-01, -3.7161e+00,\n",
      "         7.5608e-01, -5.3477e-01, -7.1966e-01,  1.2117e+00, -2.2669e+00,\n",
      "        -1.6103e+00, -5.0678e-02,  1.4072e+00, -2.9870e+00,  1.5252e+00,\n",
      "        -1.6250e+00,  8.6496e-01,  8.0231e-01,  1.5040e+00,  1.5198e+00,\n",
      "         1.2369e+00,  9.7954e-01,  1.2776e+00,  1.2508e+00,  1.1569e-01,\n",
      "        -1.3217e+00,  1.8529e+00, -2.0304e+00, -1.7047e-01, -1.4921e+00,\n",
      "         5.5576e-01,  2.2901e+00, -1.9869e+00, -6.4925e-01,  3.7939e-01,\n",
      "         1.7989e+00, -6.5865e-02, -6.7037e-01,  3.8604e+00,  1.8338e+00,\n",
      "        -2.8090e-01, -8.2520e-01,  9.0498e-01,  9.1279e-01, -8.3900e-01,\n",
      "         1.1453e+00, -9.8827e-01, -7.5140e-02,  5.3872e-01, -2.8019e+00,\n",
      "         2.0465e-01,  3.1362e-01,  1.7132e+00,  8.4356e-01,  8.7977e-02,\n",
      "        -2.3196e-01,  2.5310e-01,  1.2633e+00, -5.0723e-01,  8.1283e-01,\n",
      "        -1.5444e+00, -1.9621e-01,  1.1905e+00, -2.2130e-01,  2.0300e-01,\n",
      "        -8.9328e-01, -1.2813e+00,  1.3759e+00, -8.0671e-01, -7.3499e-01,\n",
      "        -1.6508e+00, -1.4722e+00, -7.7341e-01, -1.4518e+00, -8.5254e-02,\n",
      "         3.3558e+00,  2.3741e-02,  9.4505e-01,  5.9002e-01,  2.4458e-01,\n",
      "         1.4543e+00,  2.6747e+00, -1.7194e+00, -5.5496e-01,  1.5051e+00,\n",
      "        -7.3446e-01,  3.7696e-01,  8.6076e-02, -1.3075e+00, -1.8302e+00,\n",
      "        -6.5815e-01, -1.6453e+00, -1.4907e-01,  2.8641e-01,  1.1313e+00,\n",
      "        -9.4144e-01,  1.6367e+00,  1.5353e+00,  8.5218e-01, -2.7696e+00,\n",
      "        -1.0609e+00,  1.1823e+00, -1.2564e+00,  3.7445e-01, -1.3422e+00,\n",
      "         1.1846e-01,  7.3154e-01,  1.2686e+00,  1.9672e+00, -1.1296e+00,\n",
      "        -1.4842e-01, -2.1066e-02, -1.5841e-01, -6.7893e-01,  2.2866e+00,\n",
      "         1.1475e+00, -1.0214e+00, -6.7582e-01, -8.0994e-01,  1.4964e+00,\n",
      "         3.6446e-01,  1.7352e+00,  4.4910e+00, -1.0063e+00, -1.4515e+00,\n",
      "         5.7857e-01, -1.5296e+00, -1.2428e+00, -1.3089e+00, -2.3003e-01,\n",
      "        -1.6860e+00,  6.3637e-01,  3.5886e-01, -2.1513e+00, -1.9229e+00,\n",
      "        -1.2923e+00,  1.5814e-01, -8.3755e-01,  8.4745e-01, -6.6790e-03,\n",
      "         1.2055e+00,  3.1710e-01,  4.8037e-02, -1.9604e+00, -4.1718e+00,\n",
      "        -1.1895e+00,  2.7798e+00, -1.5361e+00,  6.6478e-01,  1.8427e+00,\n",
      "         9.8394e-02, -9.4374e-01,  2.4514e-01, -2.8145e-01, -2.2334e+00,\n",
      "        -9.5114e-01, -1.5778e-01, -2.9992e+00, -3.2876e+00, -1.1735e+00,\n",
      "         2.1052e-01,  7.6343e-01,  1.6317e+00, -1.3791e+00, -9.2411e-01,\n",
      "        -2.4325e+00, -1.8494e+00, -8.3702e-01,  8.6649e-01,  7.0998e-01,\n",
      "         8.3494e-01, -9.7865e-01,  3.0327e+00, -5.8026e-01,  6.1925e-01,\n",
      "        -3.8380e-01, -2.3082e+00,  9.9495e-02, -1.1804e+00, -1.8899e-01,\n",
      "         7.6985e-02,  1.7285e+00,  2.2692e+00, -8.6363e-01, -3.7527e-01,\n",
      "        -4.2701e-01, -1.3947e-01, -2.0410e+00, -6.2954e-01, -1.4116e+00,\n",
      "        -1.9981e+00,  1.3466e+00, -1.4862e+00, -2.1212e-02, -7.1134e-01,\n",
      "        -2.9755e-01, -6.1230e-01, -7.3787e-01, -2.3162e+00,  1.7312e+00,\n",
      "        -7.1446e-01, -1.6237e+00, -6.9911e-01, -2.7586e+00,  7.2299e-01,\n",
      "         2.8798e-01,  5.0353e-01,  1.4315e+00,  1.2262e-01,  7.8143e-01,\n",
      "         1.1213e+00,  3.9525e-01,  1.1975e-01,  6.1121e-01, -4.4783e-01,\n",
      "        -1.1471e+00, -7.1760e-01,  2.7392e-01,  1.3773e+00,  6.1961e-01,\n",
      "        -6.3805e-01,  1.7515e-01, -6.0919e-01, -4.4040e-02, -6.7796e-01,\n",
      "        -1.4665e+00, -1.7949e-01,  2.4897e+00, -3.5933e-01,  1.1911e+00,\n",
      "        -2.4533e+00, -5.3648e-01, -1.0984e+00,  6.2527e-01, -2.3473e+00,\n",
      "        -1.5014e+00,  1.8501e+00, -2.2129e+00,  2.4850e+00, -5.8636e-02,\n",
      "        -7.4231e-01,  1.8365e+00, -1.1643e+00, -2.4197e+00, -7.7334e-01,\n",
      "         1.6578e+00,  4.9968e-01,  4.4637e-01, -1.3828e-01, -1.3986e+00,\n",
      "        -9.0130e-01, -4.7513e-02, -1.2249e+00, -1.6733e+00, -2.1522e+00,\n",
      "         2.9907e-01, -1.7415e-01,  1.5391e+00,  8.9820e-01, -2.0334e-01,\n",
      "         1.5348e-01,  8.9611e-01, -4.5365e-02, -3.6143e+00, -1.8741e+00,\n",
      "         1.7157e-01,  3.6912e-01, -1.8297e+00,  2.3445e-01,  2.1479e-01],\n",
      "       device='cuda:0')\n",
      "tensor([1.3643e-06, 1.2945e-06, 8.4374e-07, 6.4035e-07, 2.5655e-07, 9.9504e-06,\n",
      "        1.1300e-06, 1.9166e-05, 3.1551e-04, 2.2732e-06, 1.0570e-06, 1.3912e-06,\n",
      "        5.9990e-07, 1.0410e-06, 1.9063e-06, 7.8902e-07, 9.5297e-07, 1.1936e-05,\n",
      "        3.6116e-06, 1.1967e-06, 6.4429e-07, 1.2895e-06, 4.1575e-07, 2.5459e-06,\n",
      "        2.7906e-07, 1.5405e-06, 3.0079e-06, 5.2704e-06, 1.2884e-06, 5.6977e-05,\n",
      "        1.8314e-06, 3.1591e-06, 1.1873e-05, 4.2196e-07, 2.3713e-06, 1.0636e-06,\n",
      "        6.5259e-07, 9.9344e-07, 2.3006e-06, 1.5493e-06, 5.7597e-07, 3.7489e-07,\n",
      "        2.3794e-07, 3.2044e-07, 2.3544e-06, 1.0402e-06, 5.0869e-06, 1.3132e-06,\n",
      "        1.1039e-07, 7.9565e-07, 7.7057e-07, 6.4722e-07, 4.8242e-06, 1.6592e-07,\n",
      "        1.4689e-06, 1.1018e-06, 1.2219e-06, 2.2007e-06, 1.5694e-06, 6.6987e-07,\n",
      "        1.0445e-05, 6.0927e-07, 2.6044e-07, 1.8439e-07, 7.4018e-07, 6.5772e-07,\n",
      "        1.8256e-06, 2.6023e-07, 7.3180e-07, 1.1469e-07, 7.6110e-07, 3.7532e-06,\n",
      "        2.9881e-07, 1.2419e-06, 8.7862e-07, 1.5433e-06, 5.9379e-07, 9.6700e-07,\n",
      "        3.9892e-05, 1.3403e-05, 1.4171e-06, 3.1531e-06, 4.6992e-06, 1.1518e-06,\n",
      "        4.4527e-06, 1.8643e-06, 3.5533e-06, 5.8385e-07, 5.7655e-07, 8.6667e-06,\n",
      "        4.5201e-07, 4.4758e-07, 1.2869e-07, 5.5598e-07, 6.3763e-07, 1.3880e-07,\n",
      "        5.1599e-07, 4.3859e-07, 1.7935e-07, 1.3115e-06, 6.3574e-06, 2.0623e-07,\n",
      "        3.2615e-06, 1.5903e-07, 1.7390e-04, 7.8076e-07, 1.7203e-05, 9.6225e-07,\n",
      "        5.3347e-06, 8.4869e-08, 2.8484e-06, 4.8569e-07, 7.7813e-06, 2.9725e-06,\n",
      "        4.5243e-06, 3.1486e-06, 3.1404e-07, 1.3676e-06, 1.5679e-06, 2.1612e-06,\n",
      "        4.1446e-07, 1.3948e-06, 3.7399e-06, 1.4933e-06, 2.5676e-06, 1.2276e-06,\n",
      "        3.7395e-06, 1.7146e-06, 1.5106e-07, 2.7073e-06, 1.5734e-06, 3.7097e-07,\n",
      "        1.7690e-06, 1.8862e-07, 2.0685e-07, 3.2520e-07, 1.6499e-06, 4.9354e-07,\n",
      "        1.9178e-07, 5.7773e-07, 1.7430e-07, 3.3619e-07, 2.1484e-07, 2.2801e-06,\n",
      "        1.6338e-06, 6.4732e-07, 8.7689e-07, 2.8727e-07, 2.3371e-07, 4.1931e-07,\n",
      "        2.6187e-07, 6.2523e-04, 1.6849e-03, 6.9454e-05, 3.8416e-04, 5.3380e-06,\n",
      "        6.4328e-06, 8.9802e-04, 1.5245e-05, 3.3032e-06, 1.1725e-06, 4.8914e-07,\n",
      "        7.0097e-07, 5.7670e-07, 2.1551e-06, 2.7529e-07, 1.3300e-06, 2.1826e-07,\n",
      "        1.4188e-06, 3.7434e-05, 7.1011e-06, 1.0582e-06, 5.4379e-07, 3.5360e-06,\n",
      "        8.7099e-05, 3.8685e-06, 5.5376e-07, 1.0737e-06, 9.2932e-07, 5.6239e-06,\n",
      "        9.7341e-06, 4.9480e-07, 6.8882e-06, 9.2838e-07, 1.9575e-06, 5.7295e-05,\n",
      "        2.8308e-04, 8.2990e-06, 9.6670e-06, 1.3866e-06, 2.9672e-06, 1.2098e-06,\n",
      "        1.3789e-04, 9.0221e-05, 2.2683e-06, 7.2420e-06, 7.5067e-07, 8.8816e-07,\n",
      "        3.9409e-07, 4.6532e-05, 1.0469e-05, 1.3908e-05, 2.1419e-06, 3.8094e-04,\n",
      "        1.0101e-05, 1.9803e-06, 5.4123e-07, 5.2672e-05, 6.4867e-06, 1.2587e-06,\n",
      "        6.8020e-07, 2.9875e-06, 9.3904e-06, 1.9674e-06, 2.5251e-06, 7.4646e-06,\n",
      "        1.6778e-05, 2.1208e-06, 2.6151e-06, 7.9086e-07, 6.4798e-06, 5.5748e-07,\n",
      "        1.0559e-03, 1.7219e-03, 6.9625e-04, 4.5965e-06, 3.5958e-05, 3.7970e-05,\n",
      "        6.6005e-05, 2.0491e-05, 9.8787e-04, 1.3608e-03, 8.0533e-04, 6.1908e-06,\n",
      "        2.3569e-06, 1.3784e-04, 2.3030e-05, 5.0664e-06, 1.2621e-06, 8.5598e-06,\n",
      "        6.7036e-06, 3.7163e-06, 3.6972e-06, 6.0195e-07, 2.3252e-05, 2.4614e-06,\n",
      "        3.0765e-06, 2.0054e-05, 6.8955e-03, 8.0045e-04, 9.2791e-04, 3.4023e-05,\n",
      "        9.4898e-06, 1.0392e-05, 3.7859e-06, 4.5196e-06, 4.6594e-05, 2.1199e-03,\n",
      "        7.9075e-01, 8.9777e-02, 1.1508e-03, 2.6814e-02, 4.8139e-06, 1.8559e-04,\n",
      "        2.3389e-05, 3.1445e-05, 1.9670e-05, 2.0621e-05, 1.0652e-06, 6.3979e-04,\n",
      "        3.6103e-02, 1.2006e-05, 3.6789e-05, 8.5825e-05, 3.0814e-04, 5.4408e-06,\n",
      "        8.2216e-06, 4.1573e-05, 3.2707e-05, 2.2788e-02, 1.1195e-04, 4.1722e-05,\n",
      "        4.9956e-05, 1.3285e-03, 6.1223e-06, 2.1842e-05, 8.2636e-07, 6.0375e-05,\n",
      "        6.2312e-06, 2.9731e-05, 2.1508e-06, 2.2650e-05, 2.0419e-05, 1.1749e-05,\n",
      "        2.2505e-06, 2.4240e-06, 1.7285e-05, 2.9559e-06, 2.6463e-06, 1.9448e-06,\n",
      "        4.1384e-07, 7.8102e-07, 7.8781e-07, 8.5714e-07, 1.0265e-06, 2.6949e-07,\n",
      "        3.4574e-06, 2.1444e-06, 9.5581e-08, 9.3096e-07, 8.7138e-06, 1.8040e-06,\n",
      "        8.2589e-07, 2.0439e-06, 2.8276e-06, 3.9820e-07, 7.1246e-07, 3.5476e-06,\n",
      "        2.0526e-06, 1.2684e-07, 4.2869e-07, 3.3442e-07, 3.7553e-07, 6.0095e-07,\n",
      "        8.6192e-07, 3.0218e-06, 1.6219e-06, 4.7091e-06, 3.6432e-06, 2.1119e-06,\n",
      "        2.1964e-05, 1.6725e-04, 9.6179e-04, 1.5189e-04, 1.3581e-05, 2.0585e-05,\n",
      "        1.9302e-06, 2.7990e-06, 2.1240e-05, 1.4275e-06, 1.5874e-06, 1.3770e-05,\n",
      "        2.0084e-06, 4.4016e-07, 2.7445e-07, 6.9985e-06, 3.8670e-06, 1.7379e-06,\n",
      "        1.2044e-05, 5.0550e-07, 3.2866e-07, 1.7548e-07, 3.1725e-07, 1.9597e-06,\n",
      "        5.8910e-07, 2.3590e-05, 2.9364e-05, 2.7382e-05, 7.6339e-05, 3.5155e-05,\n",
      "        4.0811e-07, 1.7616e-04, 9.8992e-06, 5.6549e-06, 2.7965e-07, 4.8897e-07,\n",
      "        1.8481e-07, 1.4214e-06, 5.5926e-06, 1.1438e-06, 5.6345e-07, 2.0752e-06,\n",
      "        1.0984e-06, 9.9921e-06, 9.6116e-07, 3.2368e-07, 5.2384e-08, 2.1463e-05,\n",
      "        9.5670e-07, 7.8798e-07, 3.7398e-06, 8.6038e-07, 2.1976e-06, 7.1789e-06,\n",
      "        5.1570e-06, 1.4158e-07, 1.1406e-08, 6.1676e-06, 2.3070e-06, 6.8954e-07,\n",
      "        5.9813e-07, 1.8327e-06, 6.3302e-07, 3.1002e-07, 3.6046e-07, 2.3218e-07,\n",
      "        8.3247e-07, 3.5204e-07, 4.1459e-06, 8.2421e-07, 1.9154e-07, 5.0261e-06,\n",
      "        2.0431e-06, 4.5651e-07, 6.2586e-07, 2.6884e-05, 2.7206e-07, 1.7650e-07,\n",
      "        1.9072e-06, 4.0348e-05, 2.4796e-07, 1.2251e-06, 3.9584e-06, 1.8093e-06,\n",
      "        8.2174e-07, 7.2891e-07, 5.8878e-07, 8.4455e-06, 5.3081e-06, 8.3304e-06,\n",
      "        3.7967e-06, 8.2081e-07, 6.8127e-06, 8.2059e-08, 4.3756e-08, 4.3138e-06,\n",
      "        2.5152e-06, 1.8838e-05, 2.4712e-05, 4.7968e-05, 2.5948e-06, 1.5344e-06,\n",
      "        4.1229e-07, 1.3267e-06, 2.1068e-06, 1.0748e-05, 1.1018e-06, 2.0203e-06,\n",
      "        5.7446e-07, 1.8159e-05, 2.9369e-06, 9.6544e-07, 3.7443e-06, 1.4676e-06,\n",
      "        6.5774e-06, 1.3459e-05, 4.7757e-06, 2.8846e-07, 2.4922e-06, 6.5005e-07,\n",
      "        5.6079e-05, 2.7314e-07, 4.4330e-06, 1.0049e-06, 4.0271e-07, 2.1105e-06,\n",
      "        6.0487e-06, 7.8023e-06, 1.4044e-06, 5.1699e-06, 1.2897e-06, 1.2795e-06,\n",
      "        8.4733e-06, 2.7800e-05, 1.0383e-06, 8.8511e-07, 3.9553e-07, 1.1574e-07,\n",
      "        2.5891e-06, 6.6103e-05, 6.6159e-05, 5.0686e-06, 7.0814e-06, 2.9322e-06,\n",
      "        4.6838e-07, 9.0653e-07, 3.2024e-06, 2.9487e-06, 1.1927e-05, 5.0227e-06,\n",
      "        2.2824e-07, 2.5799e-06, 4.0439e-07, 2.4521e-06, 4.0358e-06, 3.4257e-06,\n",
      "        1.4341e-06, 7.5828e-07, 1.9327e-05, 8.9163e-06, 5.6116e-07, 2.5362e-06,\n",
      "        6.8007e-07, 7.2112e-07, 1.0026e-05, 8.0647e-07, 2.2280e-06, 1.5791e-06,\n",
      "        3.4686e-07, 7.1064e-06, 5.9074e-08, 8.1284e-06, 1.2970e-05, 6.3947e-07,\n",
      "        5.2060e-06, 5.0383e-06, 1.8350e-06, 2.2323e-06, 1.2868e-05, 1.3491e-07,\n",
      "        3.8567e-06, 2.8170e-06, 4.5717e-06, 9.5979e-07, 2.5461e-07, 1.8294e-05,\n",
      "        1.7909e-06, 8.1132e-07, 2.6575e-06, 3.6137e-06, 9.0953e-07, 7.9028e-06,\n",
      "        1.2269e-05, 2.2743e-06, 4.7570e-07, 6.3952e-07, 4.0078e-07, 8.7949e-07,\n",
      "        3.9191e-06, 1.5274e-06, 1.6246e-05, 2.8533e-07, 1.9036e-06, 7.0725e-07,\n",
      "        4.3026e-06, 4.2517e-06, 9.2212e-07, 7.9498e-05, 1.1947e-06, 1.5078e-05,\n",
      "        5.8433e-07, 6.7978e-06, 8.5376e-06, 5.1028e-06, 8.6043e-06, 6.6312e-06,\n",
      "        6.2782e-06, 3.6477e-08, 7.0228e-07, 1.4556e-06, 2.4324e-07, 3.7730e-06,\n",
      "        6.0750e-05, 7.4948e-07, 7.8266e-06, 6.0281e-07, 6.0922e-06, 4.5692e-06,\n",
      "        4.4497e-06, 3.0656e-06, 1.8064e-05, 9.0479e-07, 2.1464e-06, 1.3542e-06,\n",
      "        8.5269e-07, 2.3092e-07, 1.6689e-06, 4.0973e-06, 4.1579e-06, 3.3181e-07,\n",
      "        8.5929e-07, 1.2330e-07, 1.0141e-05, 7.0571e-06, 1.0812e-05, 3.2921e-07,\n",
      "        3.4908e-07, 4.9792e-06, 2.8970e-06, 5.2635e-06, 3.7016e-06, 3.7682e-07,\n",
      "        7.9726e-07, 8.4888e-07, 2.4930e-06, 9.0410e-06, 8.1054e-07, 2.7339e-06,\n",
      "        6.5084e-07, 3.4719e-06, 3.2679e-06, 1.9106e-06, 8.5861e-07, 3.3026e-06,\n",
      "        1.1659e-05, 3.3659e-07, 7.8709e-06, 9.8247e-07, 1.0332e-06, 2.7254e-07,\n",
      "        3.8083e-06, 4.1606e-06, 9.4150e-07, 5.5875e-07, 1.2859e-06, 1.5465e-06,\n",
      "        1.4889e-05, 1.5103e-05, 3.3819e-06, 2.2119e-07, 1.5914e-06, 8.8787e-06,\n",
      "        2.4240e-07, 1.5033e-06, 2.5457e-06, 2.1461e-06, 1.4840e-06, 1.9527e-06,\n",
      "        3.8199e-06, 2.9184e-06, 2.8791e-06, 1.0475e-05, 1.1273e-05, 3.4657e-06,\n",
      "        7.6517e-07, 4.5267e-06, 2.5560e-06, 4.7290e-07, 6.1192e-06, 7.6278e-06,\n",
      "        2.7460e-06, 4.8024e-05, 9.0722e-06, 1.6833e-06, 4.0417e-07, 9.8634e-06,\n",
      "        2.8301e-06, 6.1098e-06, 3.1091e-06, 2.6466e-06, 1.0827e-06, 6.8062e-06,\n",
      "        1.3499e-06, 3.7492e-06, 6.6094e-06, 6.2553e-07, 6.8024e-06, 8.7125e-06,\n",
      "        9.6218e-07, 5.4040e-07, 4.5800e-07, 9.2340e-07, 4.0953e-06, 5.7332e-05,\n",
      "        3.2771e-07, 2.6067e-06, 7.1574e-07, 4.2474e-05, 4.1748e-06, 2.1324e-06,\n",
      "        4.3446e-07, 8.0309e-07, 1.4551e-05, 1.7981e-07, 1.1110e-05, 6.9138e-07,\n",
      "        4.8923e-06, 2.2695e-06, 1.2242e-06, 3.0489e-06, 1.2227e-06, 1.4236e-06,\n",
      "        1.1032e-06, 7.4258e-06, 1.7022e-05, 3.3424e-07, 4.8544e-05, 3.7093e-06,\n",
      "        6.9563e-07, 1.9777e-06, 2.6095e-05, 1.5742e-06, 5.0231e-07, 2.2237e-06,\n",
      "        4.3282e-06, 1.7009e-06, 2.5069e-06, 8.1778e-07, 9.1566e-06, 8.1989e-07,\n",
      "        1.9383e-06, 3.2976e-07, 1.9793e-05, 1.7082e-06, 2.1021e-06, 1.3967e-06,\n",
      "        3.9680e-07, 1.4332e-06, 9.6623e-07, 8.1888e-06, 2.5255e-05, 1.8636e-06,\n",
      "        2.2666e-07, 7.4045e-06, 1.0780e-06, 7.4960e-08, 7.5968e-07, 1.0533e-06,\n",
      "        3.0060e-06, 5.2553e-06, 2.9849e-06, 1.3047e-05, 5.2369e-06, 7.1414e-07,\n",
      "        1.5675e-06, 3.0549e-07, 1.0565e-05, 2.4076e-07, 2.4306e-06, 3.8913e-05,\n",
      "        3.2640e-06, 4.8866e-06, 4.2362e-05, 5.4277e-06, 3.8888e-07, 2.8408e-06,\n",
      "        1.4495e-07, 1.0083e-06, 1.9949e-05, 7.5649e-07, 3.2635e-06, 6.4188e-06,\n",
      "        6.5934e-07, 3.6784e-06, 6.4681e-08, 5.6625e-06, 1.5574e-06, 1.2945e-06,\n",
      "        8.9311e-06, 2.7552e-07, 5.3127e-07, 2.5272e-06, 1.0859e-05, 1.3410e-07,\n",
      "        1.2219e-05, 5.2351e-07, 6.3139e-06, 5.9305e-06, 1.1962e-05, 1.2153e-05,\n",
      "        9.1582e-06, 7.0804e-06, 9.5391e-06, 9.2867e-06, 2.9846e-06, 7.0897e-07,\n",
      "        1.6957e-05, 3.4903e-07, 2.2419e-06, 5.9789e-07, 4.6346e-06, 2.6257e-05,\n",
      "        3.6456e-07, 1.3889e-06, 3.8852e-06, 1.6066e-05, 2.4891e-06, 1.3599e-06,\n",
      "        1.2625e-04, 1.6637e-05, 2.0075e-06, 1.1649e-06, 6.5717e-06, 6.6233e-06,\n",
      "        1.1489e-06, 8.3567e-06, 9.8957e-07, 2.4661e-06, 4.5563e-06, 1.6137e-07,\n",
      "        3.2623e-06, 3.6379e-06, 1.4746e-05, 6.1802e-06, 2.9031e-06, 2.1082e-06,\n",
      "        3.4243e-06, 9.4035e-06, 1.6009e-06, 5.9932e-06, 5.6744e-07, 2.1849e-06,\n",
      "        8.7431e-06, 2.1308e-06, 3.2570e-06, 1.0882e-06, 7.3824e-07, 1.0525e-05,\n",
      "        1.1866e-06, 1.2748e-06, 5.1019e-07, 6.0995e-07, 1.2268e-06, 6.2253e-07,\n",
      "        2.4413e-06, 7.6215e-05, 2.7225e-06, 6.8404e-06, 4.7962e-06, 3.3952e-06,\n",
      "        1.1382e-05, 3.8570e-05, 4.7635e-07, 1.5263e-06, 1.1976e-05, 1.2755e-06,\n",
      "        3.8758e-06, 2.8976e-06, 7.1911e-07, 4.2639e-07, 1.3766e-06, 5.1301e-07,\n",
      "        2.2904e-06, 3.5403e-06, 8.2404e-06, 1.0370e-06, 1.3660e-05, 1.2343e-05,\n",
      "        6.2337e-06, 1.6666e-07, 9.2024e-07, 8.6720e-06, 7.5684e-07, 3.8661e-06,\n",
      "        6.9464e-07, 2.9929e-06, 5.5253e-06, 9.4538e-06, 1.9011e-05, 8.5914e-07,\n",
      "        2.2919e-06, 2.6032e-06, 2.2691e-06, 1.3483e-06, 2.6164e-05, 8.3757e-06,\n",
      "        9.5735e-07, 1.3525e-06, 1.1828e-06, 1.1873e-05, 3.8277e-06, 1.5074e-05,\n",
      "        2.3717e-04, 9.7185e-07, 6.2271e-07, 4.7415e-06, 5.7593e-07, 7.6723e-07,\n",
      "        7.1816e-07, 2.1123e-06, 4.9254e-07, 5.0237e-06, 3.8063e-06, 3.0928e-07,\n",
      "        3.8864e-07, 7.3012e-07, 3.1141e-06, 1.1506e-06, 6.2043e-06, 2.6409e-06,\n",
      "        8.8753e-06, 3.6506e-06, 2.7894e-06, 3.7435e-07, 4.1008e-08, 8.0918e-07,\n",
      "        4.2847e-05, 5.7216e-07, 5.1684e-06, 1.6785e-05, 2.9335e-06, 1.0346e-06,\n",
      "        3.3971e-06, 2.0064e-06, 2.8491e-07, 1.0270e-06, 2.2705e-06, 1.3247e-07,\n",
      "        9.9282e-08, 8.2227e-07, 3.2815e-06, 5.7043e-06, 1.3592e-05, 6.6944e-07,\n",
      "        1.0551e-06, 2.3346e-07, 4.1828e-07, 1.1512e-06, 6.3236e-06, 5.4074e-06,\n",
      "        6.1272e-06, 9.9914e-07, 5.5173e-05, 1.4881e-06, 4.9384e-06, 1.8112e-06,\n",
      "        2.6437e-07, 2.9367e-06, 8.1664e-07, 2.2008e-06, 2.8713e-06, 1.4974e-05,\n",
      "        2.5712e-05, 1.1209e-06, 1.8267e-06, 1.7346e-06, 2.3125e-06, 3.4534e-07,\n",
      "        1.4166e-06, 6.4804e-07, 3.6050e-07, 1.0220e-05, 6.0145e-07, 2.6028e-06,\n",
      "        1.3053e-06, 1.9744e-06, 1.4412e-06, 1.2712e-06, 2.6227e-07, 1.5015e-05,\n",
      "        1.3013e-06, 5.2421e-07, 1.3214e-06, 1.6851e-07, 5.4782e-06, 3.5458e-06,\n",
      "        4.3987e-06, 1.1126e-05, 3.0054e-06, 5.8080e-06, 8.1585e-06, 3.9473e-06,\n",
      "        2.9968e-06, 4.8989e-06, 1.6989e-06, 8.4423e-07, 1.2972e-06, 3.4963e-06,\n",
      "        1.0539e-05, 4.9402e-06, 1.4046e-06, 3.1675e-06, 1.4457e-06, 2.5440e-06,\n",
      "        1.3496e-06, 6.1341e-07, 2.2218e-06, 3.2056e-05, 1.8561e-06, 8.7489e-06,\n",
      "        2.2867e-07, 1.5547e-06, 8.8639e-07, 4.9682e-06, 2.5424e-07, 5.9241e-07,\n",
      "        1.6910e-05, 2.9081e-07, 3.1906e-05, 2.5072e-06, 1.2655e-06, 1.6682e-05,\n",
      "        8.2988e-07, 2.3648e-07, 1.2269e-06, 1.3952e-05, 4.3819e-06, 4.1544e-06,\n",
      "        2.3152e-06, 6.5655e-07, 1.0795e-06, 2.5352e-06, 7.8109e-07, 4.9881e-07,\n",
      "        3.0899e-07, 3.5854e-06, 2.2337e-06, 1.2389e-05, 6.5273e-06, 2.1694e-06,\n",
      "        3.0996e-06, 6.5137e-06, 2.5407e-06, 7.1614e-08, 4.0808e-07, 3.1562e-06,\n",
      "        3.8456e-06, 4.2661e-07, 3.3610e-06, 3.2956e-06], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(258, device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    model2.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model2(input_batch)\n",
    "# Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
    "print(output[0])\n",
    "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
    "print(torch.nn.functional.softmax(output[0], dim=0))\n",
    "\n",
    "result = torch.nn.functional.softmax(output[0], dim=0)\n",
    "\n",
    "result.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
